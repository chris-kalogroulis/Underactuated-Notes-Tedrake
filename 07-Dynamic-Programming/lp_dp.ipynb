{"cells":[{"block_group":"00001-142a6d01-32b5-4a15-aa12-c164d4e5d662","cell_type":"code","execution_count":null,"metadata":{"output_cleared":true,"execution_start":1644458971739,"execution_millis":1908,"source_hash":"e27e2233","id":"A4QOaw_zYLfI","deepnote_to_be_reexecuted":false,"cell_id":"5e321709c6b74ac88d79d377eedc11b5","deepnote_block_group":"00001-142a6d01-32b5-4a15-aa12-c164d4e5d662","deepnote_cell_type":"code","deepnote_sorting_key":"0","deepnote_content_hash":"e27e2233","deepnote_execution_started_at":"2022-02-10T02:09:31.739Z","deepnote_execution_finished_at":"2022-02-10T02:09:33.647Z","deepnote_source":"import matplotlib.pyplot as plt\nimport numpy as np\nfrom matplotlib import cm"},"outputs":[],"source":"import matplotlib.pyplot as plt\nimport numpy as np\nfrom matplotlib import cm"},{"block_group":"00003-e23464ff-88d3-4b47-958a-88c8f84dfc52","cell_type":"markdown","execution_count":null,"metadata":{"cell_id":"0189887517be4e999324fe1bee603759","deepnote_block_group":"00003-e23464ff-88d3-4b47-958a-88c8f84dfc52","deepnote_cell_type":"markdown","deepnote_sorting_key":"1","deepnote_source":"# The Grid World\n\nWe have seen in class that we can obtain value function using [FittedValueIteration](https://deepnote.com/workspace/Underactuated-2ed1518a-973b-4145-bd62-1768b49956a8/project/526ff99b-f112-4247-9b0b-c52f0f88d6ce/notebook/on_a_mesh-44aac282aa1a436aafb2ac6ced3f1ccb). "},"source":"# The Grid World\n\nWe have seen in class that we can obtain value function using [FittedValueIteration](https://deepnote.com/workspace/Underactuated-2ed1518a-973b-4145-bd62-1768b49956a8/project/526ff99b-f112-4247-9b0b-c52f0f88d6ce/notebook/on_a_mesh-44aac282aa1a436aafb2ac6ced3f1ccb). "},{"block_group":"00005-ed008a8e-b6be-4b57-9498-f0010fb963ab","cell_type":"markdown","execution_count":null,"metadata":{"cell_id":"557d241713a44cf69be7129471af7e12","deepnote_block_group":"00005-ed008a8e-b6be-4b57-9498-f0010fb963ab","deepnote_cell_type":"markdown","deepnote_sorting_key":"2","deepnote_source":"## Linear Programming for Dynamic Programming\n\nFor our discrete grid world, let's try to obtain the optimal cost-to-go using [linear programming](https://underactuated.csail.mit.edu/lyapunov.html#LP). Linear Programming is an optimization program with linear objective functions as well as linear equality and inequality constraints. If you are not familiar with optimization, you could take a look at the linear programming [tutorial](https://github.com/RobotLocomotion/drake/blob/master/tutorials/linear_program.ipynb) in Drake. The following cells are setting up the grid world and the transition matrix $T$ in eq(14) in the textbook."},"source":"## Linear Programming for Dynamic Programming\n\nFor our discrete grid world, let's try to obtain the optimal cost-to-go using [linear programming](https://underactuated.csail.mit.edu/lyapunov.html#LP). Linear Programming is an optimization program with linear objective functions as well as linear equality and inequality constraints. If you are not familiar with optimization, you could take a look at the linear programming [tutorial](https://github.com/RobotLocomotion/drake/blob/master/tutorials/linear_program.ipynb) in Drake. The following cells are setting up the grid world and the transition matrix $T$ in eq(14) in the textbook."},{"block_group":"00005-79c1e127-c5b6-44d4-835e-2c37185161db","cell_type":"code","execution_count":null,"metadata":{"output_cleared":true,"execution_start":1644439714617,"execution_millis":102,"source_hash":"ad8aa506","deepnote_to_be_reexecuted":false,"cell_id":"0173c803a79b4bc5824d038d215c45df","deepnote_block_group":"00005-79c1e127-c5b6-44d4-835e-2c37185161db","deepnote_cell_type":"code","deepnote_sorting_key":"3","deepnote_content_hash":"ad8aa506","deepnote_execution_started_at":"2022-02-09T20:48:34.617Z","deepnote_execution_finished_at":"2022-02-09T20:48:34.719Z","deepnote_source":"xbins = range(0, 21)\nybins = range(0, 21)\n[X, Y] = np.meshgrid(xbins, ybins)\nstates = np.vstack((X.reshape(441), Y.reshape(441)))\n\n[ux, uy] = np.meshgrid([-1, 0, 1], [-1, 0, 1])\ninputs = np.vstack((ux.reshape(9), uy.reshape(9)))\n\ngoal = [2, 8]\n\n\ndef obstacle(x):\n    return x[0] >= 6 and x[0] <= 8 and x[1] >= 4 and x[1] <= 7\n\n\nA = np.eye(2)\nB = np.eye(2)\n\ninput_dim = inputs.shape[1]\nstate_dim = states.shape[1]\n\nT = np.zeros([state_dim, state_dim, input_dim])\n\nfor i in range(input_dim):\n    for j in range(state_dim):\n        next_state = A @ states[:, j] + B @ inputs[:, i]\n        ind = np.argmin(np.linalg.norm(states.T - next_state, axis=1))\n        T[j, ind, i] = 1"},"outputs":[],"source":"xbins = range(0, 21)\nybins = range(0, 21)\n[X, Y] = np.meshgrid(xbins, ybins)\nstates = np.vstack((X.reshape(441), Y.reshape(441)))\n\n[ux, uy] = np.meshgrid([-1, 0, 1], [-1, 0, 1])\ninputs = np.vstack((ux.reshape(9), uy.reshape(9)))\n\ngoal = [2, 8]\n\n\ndef obstacle(x):\n    return x[0] >= 6 and x[0] <= 8 and x[1] >= 4 and x[1] <= 7\n\n\nA = np.eye(2)\nB = np.eye(2)\n\ninput_dim = inputs.shape[1]\nstate_dim = states.shape[1]\n\nT = np.zeros([state_dim, state_dim, input_dim])\n\nfor i in range(input_dim):\n    for j in range(state_dim):\n        next_state = A @ states[:, j] + B @ inputs[:, i]\n        ind = np.argmin(np.linalg.norm(states.T - next_state, axis=1))\n        T[j, ind, i] = 1"},{"block_group":"00006-e49c4511-a352-4c6d-b9d3-15ed353abc97","cell_type":"code","execution_count":null,"metadata":{"output_cleared":true,"execution_start":1644439716636,"execution_millis":5,"source_hash":"13e753a6","deepnote_to_be_reexecuted":false,"cell_id":"aa05a44e98604468a7030df97da4523b","deepnote_block_group":"00006-e49c4511-a352-4c6d-b9d3-15ed353abc97","deepnote_cell_type":"code","deepnote_sorting_key":"4","deepnote_content_hash":"13e753a6","deepnote_execution_started_at":"2022-02-09T20:48:36.636Z","deepnote_execution_finished_at":"2022-02-09T20:48:36.641Z","deepnote_source":"def min_time_cost(x, u):\n    state_cost = 1\n    if obstacle(x):\n        state_cost = 10\n    if np.array_equal(x, goal):\n        state_cost = 0\n    action_cost = np.linalg.norm(u, 1)\n    if action_cost > 1:\n        action_cost = 10\n    return state_cost + action_cost"},"outputs":[],"source":"def min_time_cost(x, u):\n    state_cost = 1\n    if obstacle(x):\n        state_cost = 10\n    if np.array_equal(x, goal):\n        state_cost = 0\n    action_cost = np.linalg.norm(u, 1)\n    if action_cost > 1:\n        action_cost = 10\n    return state_cost + action_cost"},{"block_group":"00007-d331d889-3006-43c0-a820-8984ec5585a1","cell_type":"markdown","execution_count":null,"metadata":{"cell_id":"ba67dc9a324d470098049b779ab76d97","deepnote_block_group":"00007-d331d889-3006-43c0-a820-8984ec5585a1","deepnote_cell_type":"markdown","deepnote_sorting_key":"5","deepnote_source":"Now it's your turn to code up the linear program for solving the optimal cost-to-go. These Drake [tutorials](https://github.com/RobotLocomotion/drake/tree/master/tutorials) could be super helpful for setting up the optimization program. To deal with numerical instability, you should use a discount factor $\\gamma$ for the Bellman update: $$ J \\leq l(a) + \\gamma T(a) J, \\quad \\forall a.$$"},"source":"Now it's your turn to code up the linear program for solving the optimal cost-to-go. These Drake [tutorials](https://github.com/RobotLocomotion/drake/tree/master/tutorials) could be super helpful for setting up the optimization program. To deal with numerical instability, you should use a discount factor $\\gamma$ for the Bellman update: $$ J \\leq l(a) + \\gamma T(a) J, \\quad \\forall a.$$"},{"block_group":"00008-e1c62275-3cdf-4482-bf3d-91d12da5737f","cell_type":"code","execution_count":null,"metadata":{"output_cleared":true,"source_hash":"b972adf3","deepnote_to_be_reexecuted":true,"cell_id":"3792131375684b659bf6a7c6e9784367","deepnote_block_group":"00008-e1c62275-3cdf-4482-bf3d-91d12da5737f","deepnote_cell_type":"code","deepnote_sorting_key":"6","deepnote_content_hash":"b972adf3","deepnote_source":"import numpy as np\nfrom pydrake.solvers import MathematicalProgram, Solve\n\n# Create an empty MathematicalProgram named prog (with no decision variables,\n# constraints or costs)\nprog = MathematicalProgram()\nJ = prog.NewContinuousVariables(state_dim, \"J\")\n\ngamma = 0.99999\n\nfor i in range(input_dim):\n    l = np.zeros(state_dim)\n    for j in range(state_dim):\n        ## Calculate\n        l[j] = 0  # modify here\n        ## Modify here\n        ## Add Constraint for each entry of J\n\n\n## Modify here\n## Add cost to prog\n\n\nresult = Solve(prog)\nJ_value = np.reshape(result.GetSolution(J), X.shape)"},"outputs":[],"source":"import numpy as np\nfrom pydrake.solvers import MathematicalProgram, Solve\n\n# Create an empty MathematicalProgram named prog (with no decision variables,\n# constraints or costs)\nprog = MathematicalProgram()\nJ = prog.NewContinuousVariables(state_dim, \"J\")\n\ngamma = 0.99999\n\nfor i in range(input_dim):\n    l = np.zeros(state_dim)\n    for j in range(state_dim):\n        ## Calculate\n        l[j] = 0  # modify here\n        ## Modify here\n        ## Add Constraint for each entry of J\n\n\n## Modify here\n## Add cost to prog\n\n\nresult = Solve(prog)\nJ_value = np.reshape(result.GetSolution(J), X.shape)"},{"block_group":"00010-de467e71-3ce0-4256-a888-b49a5603b84f","cell_type":"markdown","execution_count":null,"metadata":{"cell_id":"6a1d8524d9c34bffb03797f04dc4e476","deepnote_block_group":"00010-de467e71-3ce0-4256-a888-b49a5603b84f","deepnote_cell_type":"markdown","deepnote_sorting_key":"7","deepnote_source":"Let's visualize the value function you calculated using LP. It should be similiar to the plot obtained from FittedValueIteration."},"source":"Let's visualize the value function you calculated using LP. It should be similiar to the plot obtained from FittedValueIteration."},{"block_group":"00011-2ab52873-bb28-46fa-8dcc-80826da81f71","cell_type":"code","execution_count":null,"metadata":{"output_cleared":true,"execution_start":1644439733628,"execution_millis":195,"source_hash":"53bd7a35","deepnote_output_heights":[280],"deepnote_to_be_reexecuted":false,"cell_id":"2415bb4f5752403ab2e1de35076c7fd1","deepnote_block_group":"00011-2ab52873-bb28-46fa-8dcc-80826da81f71","deepnote_cell_type":"code","deepnote_sorting_key":"8","deepnote_content_hash":"53bd7a35","deepnote_execution_started_at":"2022-02-09T20:48:53.628Z","deepnote_execution_finished_at":"2022-02-09T20:48:53.823Z","deepnote_source":"(fig, ax) = plt.subplots()\nax.set_xlabel(\"x\")\nax.set_ylabel(\"y\")\nax.set_title(\"Cost-to-Go\")\nk = ax.imshow(J_value, cmap=cm.jet)\nax.invert_yaxis()\nplt.colorbar(k)\nplt.show()"},"outputs":[],"source":"(fig, ax) = plt.subplots()\nax.set_xlabel(\"x\")\nax.set_ylabel(\"y\")\nax.set_title(\"Cost-to-Go\")\nk = ax.imshow(J_value, cmap=cm.jet)\nax.invert_yaxis()\nplt.colorbar(k)\nplt.show()"},{"block_group":"00012-36305c01-3e51-4723-8be0-f3fc9728f140","cell_type":"markdown","execution_count":null,"metadata":{"cell_id":"5ea10eef90c04b71a66c6dfc84b424af","deepnote_block_group":"00012-36305c01-3e51-4723-8be0-f3fc9728f140","deepnote_cell_type":"markdown","deepnote_sorting_key":"9","deepnote_source":"## Autograding\nYou can check your work by running the following cell:"},"source":"## Autograding\nYou can check your work by running the following cell:"},{"block_group":"00013-f5299738-e0e5-4ec8-9b8a-c4cb6ecdd304","cell_type":"code","execution_count":null,"metadata":{"output_cleared":true,"execution_start":1644439736206,"execution_millis":1000,"source_hash":"8427ffb4","deepnote_to_be_reexecuted":false,"cell_id":"2ccc35eada54493d8c049fc0eb26c906","deepnote_block_group":"00013-f5299738-e0e5-4ec8-9b8a-c4cb6ecdd304","deepnote_cell_type":"code","deepnote_sorting_key":"10","deepnote_content_hash":"8427ffb4","deepnote_execution_started_at":"2022-02-09T20:48:56.206Z","deepnote_execution_finished_at":"2022-02-09T20:48:57.206Z","deepnote_source":"from underactuated.exercises.dp.test_lp_dp import Testlpdp\nfrom underactuated.exercises.grader import Grader\n\nGrader.grade_output([Testlpdp], [locals()], \"results.json\")\nGrader.print_test_results(\"results.json\")"},"outputs":[],"source":"from underactuated.exercises.dp.test_lp_dp import Testlpdp\nfrom underactuated.exercises.grader import Grader\n\nGrader.grade_output([Testlpdp], [locals()], \"results.json\")\nGrader.print_test_results(\"results.json\")"},{"block_group":"00014-3bf31a41-9058-40e9-b82f-959f8ef2ff0c","cell_type":"code","execution_count":null,"metadata":{"output_cleared":true,"source_hash":"b623e53d","deepnote_to_be_reexecuted":true,"cell_id":"7d2b3742c0cd400fb09a93915f9e2440","deepnote_block_group":"00014-3bf31a41-9058-40e9-b82f-959f8ef2ff0c","deepnote_cell_type":"code","deepnote_sorting_key":"11","deepnote_content_hash":"b623e53d","deepnote_source":""},"outputs":[],"source":""}],
        "metadata": {"deepnote_notebook_id":"eaab123f7a094a22b8683cbb735c47f4"},
        "nbformat": "4",
        "nbformat_minor": "0",
        "version": "0"
      }