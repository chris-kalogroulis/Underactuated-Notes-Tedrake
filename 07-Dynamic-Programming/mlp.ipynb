{"cells":[{"block_group":"7ca13a766d464dfebe4c141791389a1e","cell_type":"markdown","execution_count":null,"metadata":{"id":"TKvYiJgnYExi","cell_id":"408990ae9b28496fa60b4cb782674dc8","deepnote_block_group":"7ca13a766d464dfebe4c141791389a1e","deepnote_cell_type":"markdown","deepnote_sorting_key":"0","deepnote_source":"This notebook provides examples to go along with the [textbook](https://underactuated.csail.mit.edu/dp.html).  I recommend having both windows open, side-by-side!\n"},"source":"This notebook provides examples to go along with the [textbook](https://underactuated.csail.mit.edu/dp.html).  I recommend having both windows open, side-by-side!\n"},{"block_group":"0d8320f4b85446f2b44c2e48d7fd9693","cell_type":"code","execution_count":null,"metadata":{"id":"A4QOaw_zYLfI","cell_id":"e41eac143fd54527a31dede8bf59d19a","deepnote_block_group":"0d8320f4b85446f2b44c2e48d7fd9693","deepnote_cell_type":"code","deepnote_sorting_key":"1","deepnote_source":"import matplotlib.pyplot as plt\nimport numpy as np\nfrom IPython.display import clear_output, display\nfrom matplotlib import cm\nfrom pydrake.all import (\n    DiagramBuilder,\n    DiscreteAlgebraicRiccatiEquation,\n    LeafSystem,\n    LinearSystem,\n    MeshcatVisualizer,\n    MultilayerPerceptron,\n    PerceptronActivationType,\n    RandomGenerator,\n    Rgba,\n    RigidTransform,\n    RotationMatrix,\n    SceneGraph,\n    Simulator,\n    StartMeshcat,\n    ZeroOrderHold,\n)\nfrom pydrake.examples import AcrobotPlant, PendulumGeometry, PendulumPlant\n\nfrom underactuated.jupyter import running_as_notebook\nfrom underactuated.optimizers import Adam"},"outputs":[],"source":"import matplotlib.pyplot as plt\nimport numpy as np\nfrom IPython.display import clear_output, display\nfrom matplotlib import cm\nfrom pydrake.all import (\n    DiagramBuilder,\n    DiscreteAlgebraicRiccatiEquation,\n    LeafSystem,\n    LinearSystem,\n    MeshcatVisualizer,\n    MultilayerPerceptron,\n    PerceptronActivationType,\n    RandomGenerator,\n    Rgba,\n    RigidTransform,\n    RotationMatrix,\n    SceneGraph,\n    Simulator,\n    StartMeshcat,\n    ZeroOrderHold,\n)\nfrom pydrake.examples import AcrobotPlant, PendulumGeometry, PendulumPlant\n\nfrom underactuated.jupyter import running_as_notebook\nfrom underactuated.optimizers import Adam"},{"block_group":"812ebcb5bd864a4098cfe9cd0acd64ef","cell_type":"code","execution_count":null,"metadata":{"cell_id":"c7626b0ad99146df8b1d89e98b48afe3","deepnote_block_group":"812ebcb5bd864a4098cfe9cd0acd64ef","deepnote_cell_type":"code","deepnote_sorting_key":"2","deepnote_source":"# Start the visualizer (run this cell only once, each instance consumes a port)\nmeshcat = StartMeshcat()"},"outputs":[],"source":"# Start the visualizer (run this cell only once, each instance consumes a port)\nmeshcat = StartMeshcat()"},{"block_group":"4f536986d75f4f548a7b68244727c443","cell_type":"markdown","execution_count":null,"metadata":{"cell_id":"d9d01956fed4477c9b74b0b2e4a5745b","deepnote_block_group":"4f536986d75f4f548a7b68244727c443","deepnote_cell_type":"markdown","deepnote_sorting_key":"3","deepnote_source":"# Neural Fitted Value Iteration"},"source":"# Neural Fitted Value Iteration"},{"block_group":"a826be34b8e74e19814e980373fa59f9","cell_type":"code","execution_count":null,"metadata":{"cell_id":"41d2a8ea14ad473c83c3f19bfc25baea","deepnote_block_group":"a826be34b8e74e19814e980373fa59f9","deepnote_cell_type":"code","deepnote_sorting_key":"4","deepnote_source":"# Define the double integrator\nA = np.array([[0.0, 1.0], [0.0, 0.0]])\nB = np.array([[0.0], [1.0]])\nQ = 0.1 * np.eye(2)\nR = np.eye(1)\n\n\n# vectorized\ndef min_time_cost(x, u):\n    return 1.0 - np.isclose(x, np.zeros((2, 1))).all(axis=0)\n\n\ndef quadratic_regulator_cost(x, u):\n    return (x * (Q @ x)).sum(axis=0) + (u * (R @ u)).sum(axis=0)\n\n\ndef min_time_solution(x, time_step, discount_factor=1):\n    # Caveat: this does not take the zero-order hold on u into account\n\n    q = x[0, :]\n    qdot = x[1, :]\n    # mask indicates that we are in the regime where u = +1.\n    mask = ((qdot < 0) & (2 * q <= (qdot**2))) | ((qdot >= 0) & (2 * q < -(qdot**2)))\n    T = np.empty(q.size)\n    T[mask] = 2 * np.sqrt(0.5 * qdot[mask] ** 2 - q[mask]) - qdot[mask]\n    T[~mask] = qdot[~mask] + 2 * np.sqrt(0.5 * qdot[~mask] ** 2 + q[~mask])\n\n    if discount_factor == 1:\n        return T\n    else:\n        # discount in continuous time looks like e^(-t/tau), with e^(-time_step/tau) = discount_factor; or -time_step/tau = ln(discount_factor)\n        tau = -time_step / np.log(discount_factor)\n        # ∫₀ᵀ exp(−t/τ) dt = τ [1 − exp(-T/τ)]\n        return tau * (1 - np.exp(-T / tau))\n\n\ndef quadratic_regulator_solution(x, time_step, discount_factor=1):\n    S = DiscreteAlgebraicRiccatiEquation(\n        A=np.sqrt(discount_factor) * (np.eye(2) + time_step * A),\n        B=time_step * B,\n        Q=time_step * Q,\n        R=time_step * R / discount_factor,\n    )\n    return (x * (S @ x)).sum(axis=0)\n\n\ndef plot_and_compare(mlp, context, running_cost, time_step, discount_factor=1.0):\n    x1s = np.linspace(-5, 5, 31)\n    x2s = np.linspace(-4, 4, 51)\n    X1s, X2s = np.meshgrid(x1s, x2s)\n    N = X1s.size\n    X = np.vstack((X1s.flatten(), X2s.flatten()))\n    J = np.zeros((1, N))\n\n    mlp.BatchOutput(context, X, J)\n\n    meshcat.PlotSurface(\n        \"Jhat\",\n        X1s,\n        X2s,\n        J.reshape(X1s.shape),\n        rgba=Rgba(0, 0, 1),\n        wireframe=True,\n    )\n\n    if running_cost == min_time_cost:\n        Jd = min_time_solution(X, time_step, discount_factor)\n    elif running_cost == quadratic_regulator_cost:\n        Jd = quadratic_regulator_solution(X, time_step, discount_factor)\n\n    meshcat.PlotSurface(\n        \"J_desired\",\n        X1s,\n        X2s,\n        Jd.reshape(X1s.shape),\n        rgba=Rgba(1, 0, 0),\n        wireframe=True,\n    )"},"outputs":[],"source":"# Define the double integrator\nA = np.array([[0.0, 1.0], [0.0, 0.0]])\nB = np.array([[0.0], [1.0]])\nQ = 0.1 * np.eye(2)\nR = np.eye(1)\n\n\n# vectorized\ndef min_time_cost(x, u):\n    return 1.0 - np.isclose(x, np.zeros((2, 1))).all(axis=0)\n\n\ndef quadratic_regulator_cost(x, u):\n    return (x * (Q @ x)).sum(axis=0) + (u * (R @ u)).sum(axis=0)\n\n\ndef min_time_solution(x, time_step, discount_factor=1):\n    # Caveat: this does not take the zero-order hold on u into account\n\n    q = x[0, :]\n    qdot = x[1, :]\n    # mask indicates that we are in the regime where u = +1.\n    mask = ((qdot < 0) & (2 * q <= (qdot**2))) | ((qdot >= 0) & (2 * q < -(qdot**2)))\n    T = np.empty(q.size)\n    T[mask] = 2 * np.sqrt(0.5 * qdot[mask] ** 2 - q[mask]) - qdot[mask]\n    T[~mask] = qdot[~mask] + 2 * np.sqrt(0.5 * qdot[~mask] ** 2 + q[~mask])\n\n    if discount_factor == 1:\n        return T\n    else:\n        # discount in continuous time looks like e^(-t/tau), with e^(-time_step/tau) = discount_factor; or -time_step/tau = ln(discount_factor)\n        tau = -time_step / np.log(discount_factor)\n        # ∫₀ᵀ exp(−t/τ) dt = τ [1 − exp(-T/τ)]\n        return tau * (1 - np.exp(-T / tau))\n\n\ndef quadratic_regulator_solution(x, time_step, discount_factor=1):\n    S = DiscreteAlgebraicRiccatiEquation(\n        A=np.sqrt(discount_factor) * (np.eye(2) + time_step * A),\n        B=time_step * B,\n        Q=time_step * Q,\n        R=time_step * R / discount_factor,\n    )\n    return (x * (S @ x)).sum(axis=0)\n\n\ndef plot_and_compare(mlp, context, running_cost, time_step, discount_factor=1.0):\n    x1s = np.linspace(-5, 5, 31)\n    x2s = np.linspace(-4, 4, 51)\n    X1s, X2s = np.meshgrid(x1s, x2s)\n    N = X1s.size\n    X = np.vstack((X1s.flatten(), X2s.flatten()))\n    J = np.zeros((1, N))\n\n    mlp.BatchOutput(context, X, J)\n\n    meshcat.PlotSurface(\n        \"Jhat\",\n        X1s,\n        X2s,\n        J.reshape(X1s.shape),\n        rgba=Rgba(0, 0, 1),\n        wireframe=True,\n    )\n\n    if running_cost == min_time_cost:\n        Jd = min_time_solution(X, time_step, discount_factor)\n    elif running_cost == quadratic_regulator_cost:\n        Jd = quadratic_regulator_solution(X, time_step, discount_factor)\n\n    meshcat.PlotSurface(\n        \"J_desired\",\n        X1s,\n        X2s,\n        Jd.reshape(X1s.shape),\n        rgba=Rgba(1, 0, 0),\n        wireframe=True,\n    )"},{"block_group":"386e405bf1ed43e286c088afa60f6aed","cell_type":"markdown","execution_count":null,"metadata":{"cell_id":"8f5694ca7c9647afbca81a6e8b167b19","deepnote_block_group":"386e405bf1ed43e286c088afa60f6aed","deepnote_cell_type":"markdown","deepnote_sorting_key":"5","deepnote_source":"First, let's simply evaluate how well the network can fit the known cost-to-go functions (using supervised learning)"},"source":"First, let's simply evaluate how well the network can fit the known cost-to-go functions (using supervised learning)"},{"block_group":"1e936fa06c1d44ff9119f67b4429c70f","cell_type":"code","execution_count":null,"metadata":{"cell_id":"dd2248dcb50b4715993aff457c113638","deepnote_block_group":"1e936fa06c1d44ff9119f67b4429c70f","deepnote_cell_type":"code","deepnote_sorting_key":"6","deepnote_source":"def SupervisedDemo(running_cost, time_step, discount_factor=1.0):\n    x1s = np.linspace(-5, 5, 51)\n    x2s = np.linspace(-4, 4, 51)\n    X1s, X2s = np.meshgrid(x1s, x2s)\n    N = X1s.size\n    X = np.vstack((X1s.flatten(), X2s.flatten()))\n\n    if running_cost == min_time_cost:\n        Jd = min_time_solution(X, time_step, discount_factor)\n    elif running_cost == quadratic_regulator_cost:\n        Jd = quadratic_regulator_solution(X, time_step, discount_factor)\n\n    Jd = Jd.reshape((1, N))\n\n    mlp = MultilayerPerceptron(\n        [2, 64, 64, 1] if running_cost == min_time_cost else [2, 16, 16, 1],\n        [\n            PerceptronActivationType.kReLU,\n            PerceptronActivationType.kReLU,\n            PerceptronActivationType.kIdentity,\n        ],\n    )\n    context = mlp.CreateDefaultContext()\n    generator = RandomGenerator(152)\n    mlp.SetRandomContext(context, generator)\n\n    optimizer = Adam(mlp.GetMutableParameters(context))\n\n    dloss_dparams = np.zeros(mlp.num_parameters())\n    last_loss = np.inf\n    for epoch in range(2000 if running_as_notebook else 2):\n        loss = mlp.BackpropagationMeanSquaredError(context, X, Jd, dloss_dparams)\n        if epoch % 20 == 0:\n            clear_output(wait=True)\n            print(f\"loss = {loss}\")\n        if np.linalg.norm(last_loss - loss) < 1e-6:\n            break\n        last_loss = loss\n        optimizer.step(loss, dloss_dparams)\n\n    plot_and_compare(mlp, context, running_cost, time_step, discount_factor)\n\n\nmeshcat.Delete()\nSupervisedDemo(min_time_cost, 0.1, 0.98)\n# SupervisedDemo(quadratic_regulator_cost, 0.1)"},"outputs":[],"source":"def SupervisedDemo(running_cost, time_step, discount_factor=1.0):\n    x1s = np.linspace(-5, 5, 51)\n    x2s = np.linspace(-4, 4, 51)\n    X1s, X2s = np.meshgrid(x1s, x2s)\n    N = X1s.size\n    X = np.vstack((X1s.flatten(), X2s.flatten()))\n\n    if running_cost == min_time_cost:\n        Jd = min_time_solution(X, time_step, discount_factor)\n    elif running_cost == quadratic_regulator_cost:\n        Jd = quadratic_regulator_solution(X, time_step, discount_factor)\n\n    Jd = Jd.reshape((1, N))\n\n    mlp = MultilayerPerceptron(\n        [2, 64, 64, 1] if running_cost == min_time_cost else [2, 16, 16, 1],\n        [\n            PerceptronActivationType.kReLU,\n            PerceptronActivationType.kReLU,\n            PerceptronActivationType.kIdentity,\n        ],\n    )\n    context = mlp.CreateDefaultContext()\n    generator = RandomGenerator(152)\n    mlp.SetRandomContext(context, generator)\n\n    optimizer = Adam(mlp.GetMutableParameters(context))\n\n    dloss_dparams = np.zeros(mlp.num_parameters())\n    last_loss = np.inf\n    for epoch in range(2000 if running_as_notebook else 2):\n        loss = mlp.BackpropagationMeanSquaredError(context, X, Jd, dloss_dparams)\n        if epoch % 20 == 0:\n            clear_output(wait=True)\n            print(f\"loss = {loss}\")\n        if np.linalg.norm(last_loss - loss) < 1e-6:\n            break\n        last_loss = loss\n        optimizer.step(loss, dloss_dparams)\n\n    plot_and_compare(mlp, context, running_cost, time_step, discount_factor)\n\n\nmeshcat.Delete()\nSupervisedDemo(min_time_cost, 0.1, 0.98)\n# SupervisedDemo(quadratic_regulator_cost, 0.1)"},{"block_group":"af908174ce3a4440853f0379a3db400e","cell_type":"markdown","execution_count":null,"metadata":{"cell_id":"dc86b3f979c547e185f35bfd28e1e363","deepnote_block_group":"af908174ce3a4440853f0379a3db400e","deepnote_cell_type":"markdown","deepnote_sorting_key":"7","deepnote_source":"## Discrete time, continuous state, discrete action\n\nThis is the standard \"fitted value iteration\" algorithm with a multilayer perceptron (MLP) as the function approximator, and a single step of gradient descent performed on each iteration."},"source":"## Discrete time, continuous state, discrete action\n\nThis is the standard \"fitted value iteration\" algorithm with a multilayer perceptron (MLP) as the function approximator, and a single step of gradient descent performed on each iteration."},{"block_group":"1328f27c98bc4345b1c577dd96c96462","cell_type":"code","execution_count":null,"metadata":{"cell_id":"25ae2acc9f4e4d09b8119c1daf53ab26","deepnote_block_group":"1328f27c98bc4345b1c577dd96c96462","deepnote_cell_type":"code","deepnote_sorting_key":"8","deepnote_source":"def FittedValueIteration(running_cost, time_step, discount_factor=0.9):\n    x1s = np.linspace(-5, 5, 31)\n    x2s = np.linspace(-4, 4, 31)\n    us = np.linspace(-1, 1, 9)\n    Us, X1s, X2s = np.meshgrid(us, x1s, x2s, indexing=\"ij\")\n    XwithU = np.vstack((X1s.flatten(), X2s.flatten()))\n    UwithX = Us.flatten().reshape(1, -1)\n    Nx = x1s.size * x2s.size\n    X = XwithU[:, :Nx]\n    N = X1s.size\n\n    Xnext = XwithU + time_step * (A @ XwithU + B @ UwithX)\n    Cost = time_step * running_cost(XwithU, UwithX)\n    Jnext = np.zeros((1, N))\n    Jd = np.zeros((1, Nx))\n\n    mlp = MultilayerPerceptron(\n        [2, 100, 100, 1] if running_cost == min_time_cost else [2, 16, 16, 1],\n        [\n            PerceptronActivationType.kReLU,\n            PerceptronActivationType.kReLU,\n            PerceptronActivationType.kIdentity,\n        ],\n    )\n    context = mlp.CreateDefaultContext()\n    generator = RandomGenerator(123)\n    mlp.SetRandomContext(context, generator)\n\n    optimizer = Adam(mlp.GetMutableParameters(context))\n\n    plot_and_compare(mlp, context, running_cost, time_step, discount_factor)\n    dloss_dparams = np.zeros(mlp.num_parameters())\n    last_loss = np.inf\n    for epoch in range(500 if running_as_notebook else 2):\n        mlp.BatchOutput(context, Xnext, Jnext)\n        Jd[:] = np.min((Cost + discount_factor * Jnext).reshape(us.size, Nx), axis=0)\n        for i in range(100 if running_as_notebook else 2):\n            loss = mlp.BackpropagationMeanSquaredError(context, X, Jd, dloss_dparams)\n            optimizer.step(loss, dloss_dparams)\n        if np.linalg.norm(last_loss - loss) < 1e-8:\n            break\n        last_loss = loss\n        clear_output(wait=True)\n        print(f\"epoch {epoch}: loss = {loss}\")\n        if epoch % 10 == 0:\n            plot_and_compare(mlp, context, running_cost, time_step, discount_factor)\n\n    plot_and_compare(mlp, context, running_cost, time_step, discount_factor)\n\n\nFittedValueIteration(min_time_cost, 0.1, discount_factor=0.95)\n\n# FittedValueIteration(quadratic_regulator_cost, 0.1, discount_factor=0.9)"},"outputs":[],"source":"def FittedValueIteration(running_cost, time_step, discount_factor=0.9):\n    x1s = np.linspace(-5, 5, 31)\n    x2s = np.linspace(-4, 4, 31)\n    us = np.linspace(-1, 1, 9)\n    Us, X1s, X2s = np.meshgrid(us, x1s, x2s, indexing=\"ij\")\n    XwithU = np.vstack((X1s.flatten(), X2s.flatten()))\n    UwithX = Us.flatten().reshape(1, -1)\n    Nx = x1s.size * x2s.size\n    X = XwithU[:, :Nx]\n    N = X1s.size\n\n    Xnext = XwithU + time_step * (A @ XwithU + B @ UwithX)\n    Cost = time_step * running_cost(XwithU, UwithX)\n    Jnext = np.zeros((1, N))\n    Jd = np.zeros((1, Nx))\n\n    mlp = MultilayerPerceptron(\n        [2, 100, 100, 1] if running_cost == min_time_cost else [2, 16, 16, 1],\n        [\n            PerceptronActivationType.kReLU,\n            PerceptronActivationType.kReLU,\n            PerceptronActivationType.kIdentity,\n        ],\n    )\n    context = mlp.CreateDefaultContext()\n    generator = RandomGenerator(123)\n    mlp.SetRandomContext(context, generator)\n\n    optimizer = Adam(mlp.GetMutableParameters(context))\n\n    plot_and_compare(mlp, context, running_cost, time_step, discount_factor)\n    dloss_dparams = np.zeros(mlp.num_parameters())\n    last_loss = np.inf\n    for epoch in range(500 if running_as_notebook else 2):\n        mlp.BatchOutput(context, Xnext, Jnext)\n        Jd[:] = np.min((Cost + discount_factor * Jnext).reshape(us.size, Nx), axis=0)\n        for i in range(100 if running_as_notebook else 2):\n            loss = mlp.BackpropagationMeanSquaredError(context, X, Jd, dloss_dparams)\n            optimizer.step(loss, dloss_dparams)\n        if np.linalg.norm(last_loss - loss) < 1e-8:\n            break\n        last_loss = loss\n        clear_output(wait=True)\n        print(f\"epoch {epoch}: loss = {loss}\")\n        if epoch % 10 == 0:\n            plot_and_compare(mlp, context, running_cost, time_step, discount_factor)\n\n    plot_and_compare(mlp, context, running_cost, time_step, discount_factor)\n\n\nFittedValueIteration(min_time_cost, 0.1, discount_factor=0.95)\n\n# FittedValueIteration(quadratic_regulator_cost, 0.1, discount_factor=0.9)"},{"block_group":"43f25ac531c042119b4b186abda0a4bb","cell_type":"markdown","execution_count":null,"metadata":{"cell_id":"24437d96818444d9a53705fd6224649a","deepnote_block_group":"43f25ac531c042119b4b186abda0a4bb","deepnote_cell_type":"markdown","deepnote_sorting_key":"9","deepnote_source":"## Continuous-time, state, and actions\n\nI've written this to take an arbitrary system as the input.  It requires that the system has only continuous-time dynamics, and it assumes (currently without checking) that the system is control affine."},"source":"## Continuous-time, state, and actions\n\nI've written this to take an arbitrary system as the input.  It requires that the system has only continuous-time dynamics, and it assumes (currently without checking) that the system is control affine."},{"block_group":"8dd384bde8bd4238b5257c235976524c","cell_type":"code","execution_count":null,"metadata":{"cell_id":"11dc17ca1cec40929739f7282380f7d2","deepnote_block_group":"8dd384bde8bd4238b5257c235976524c","deepnote_cell_type":"code","deepnote_sorting_key":"10","deepnote_source":"def ContinuousFittedValueIteration(\n    plant,\n    plant_context,\n    value_mlp,\n    state_cost_function,\n    R_diag,\n    state_samples,\n    time_step=0.01,\n    discount_factor=1.0,\n    input_port_index=0,\n    lr=0.001,\n    minibatch=None,\n    epochs=1000,\n    optim_steps_per_epoch=25,\n    input_limits=None,\n):\n    input_port = plant.get_input_port(input_port_index)\n    num_states = plant.num_continuous_states()\n    num_inputs = input_port.size()\n    N = state_samples.shape[1]\n\n    # assert plant.ValidateContext(plant_context)  # TODO(russt): bind this\n    assert plant_context.has_only_continuous_state()\n    assert value_mlp.get_input_port().size() == num_states\n    assert value_mlp.layers()[-1] == 1\n    assert R_diag.shape == (num_inputs,)\n    assert state_samples.shape[0] == num_states\n    assert time_step > 0.0\n    assert discount_factor > 0.0 and discount_factor <= 1.0\n    if input_limits != None:\n        assert (\n            num_inputs == 1\n        ), \"Input limits are only supported for scalar inputs (for now)\"\n        assert len(input_limits) == 2\n\n    mlp_context = value_mlp.CreateDefaultContext()\n    generator = RandomGenerator(123)\n    value_mlp.SetRandomContext(mlp_context, generator)\n\n    state_cost = state_cost_function(state_samples)\n    state_dynamics_x = np.empty((N, num_states))\n    dstate_dynamics_du = [np.empty((num_states, N))] * num_inputs\n    Rinv = 1 / R_diag\n\n    state = plant_context.get_mutable_continuous_state_vector()\n\n    # Precompute dynamics and cost (TODO: parallelize this).\n    for i in range(N):\n        u = np.zeros(num_inputs)\n        input_port.FixValue(plant_context, u)\n        state.SetFromVector(state_samples[:, i])\n        state_dynamics_x[i] = plant.EvalTimeDerivatives(plant_context).CopyToVector()\n        for j in range(num_inputs):\n            u[j] = 1\n            input_port.FixValue(plant_context, u)\n            dstate_dynamics_du[j][:, i] = (\n                plant.EvalTimeDerivatives(plant_context).CopyToVector()\n                - state_dynamics_x[i]\n            )\n            u[j] = 0\n\n    optimizer = Adam(value_mlp.GetMutableParameters(mlp_context), lr=lr)\n\n    M = minibatch if minibatch else N\n    J = np.zeros((1, M))\n    Jnext = np.zeros((1, M))\n    Jd = np.zeros((1, M))\n    dJdX = np.asfortranarray(np.zeros((num_states, M)))\n    dloss_dparams = np.zeros(value_mlp.num_parameters())\n    last_loss = np.inf\n    for epoch in range(epochs if running_as_notebook else 2):\n        if minibatch:\n            batch = np.random.randint(0, N, minibatch)\n        else:\n            batch = range(N)\n        value_mlp.BatchOutput(mlp_context, state_samples[:, batch], J, dJdX)\n        Xnext = state_samples[:, batch] + time_step * state_dynamics_x[batch, :].T\n        G = state_cost[batch]\n        for i in range(num_inputs):\n            ui = -0.5 * Rinv[i] * np.sum(dstate_dynamics_du[i][:, batch] * dJdX, 0)\n            if input_limits != None:\n                ui = np.minimum(np.maximum(ui, input_limits[0]), input_limits[1])\n            G += R_diag[i] * ui**2\n            Xnext += time_step * dstate_dynamics_du[i][:, batch] * ui\n        value_mlp.BatchOutput(mlp_context, Xnext, Jnext)\n        Jd[:] = G * time_step + discount_factor * Jnext\n        for i in range(optim_steps_per_epoch if running_as_notebook else 2):\n            loss = value_mlp.BackpropagationMeanSquaredError(\n                mlp_context, state_samples[:, batch], Jd, dloss_dparams\n            )\n            optimizer.step(loss, dloss_dparams)\n        if not minibatch and np.linalg.norm(last_loss - loss) < 1e-8:\n            break\n        last_loss = loss\n        if epoch % 20 == 0:\n            clear_output(wait=True)\n            print(f\"epoch {epoch}: loss = {loss}\")\n\n    return mlp_context\n\n\nclass ContinuousFittedValueIterationPolicy(LeafSystem):\n    def __init__(\n        self,\n        plant,\n        value_mlp,\n        value_mlp_context,\n        R_diag,\n        input_port_index=0,\n        input_limits=None,\n    ):\n        LeafSystem.__init__(self)\n\n        num_plant_states = value_mlp.get_input_port().size()\n        self._plant = plant\n        self._plant_context = plant.CreateDefaultContext()\n\n        self.value_mlp = value_mlp\n        self.value_mlp_context = value_mlp_context\n        self.J = np.zeros((1, 1))\n        self.dJdX = np.asfortranarray(np.zeros((num_plant_states, 1)))\n\n        self.Rinv = 1 / R_diag\n        self.input_limits = input_limits\n        self.DeclareVectorInputPort(\"plant_state\", num_plant_states)\n        self._plant_input_port = self._plant.get_input_port(input_port_index)\n        self.DeclareVectorOutputPort(\n            \"output\", self._plant_input_port.size(), self.CalcOutput\n        )\n\n    def CalcOutput(self, context, output):\n        num_inputs = self._plant_input_port.size()\n        u = np.zeros(num_inputs)\n        plant_state = self.get_input_port().Eval(context)\n\n        self.value_mlp.BatchOutput(\n            self.value_mlp_context,\n            np.atleast_2d(plant_state).T,\n            self.J,\n            self.dJdX,\n        )\n\n        self._plant_context.SetContinuousState(plant_state)\n        self._plant_input_port.FixValue(self._plant_context, u)\n        state_dynamics_x = self._plant.EvalTimeDerivatives(\n            self._plant_context\n        ).CopyToVector()\n        for i in range(num_inputs):\n            u[i] = 1\n            self._plant_input_port.FixValue(self._plant_context, u)\n            dstate_dynamics_dui = (\n                self._plant.EvalTimeDerivatives(self._plant_context).CopyToVector()\n                - state_dynamics_x\n            )\n            ui = -0.5 * self.Rinv[i] * dstate_dynamics_dui.dot(self.dJdX)\n            if self.input_limits != None:\n                ui = np.minimum(\n                    np.maximum(ui, self.input_limits[0]), self.input_limits[1]\n                )\n            output.SetAtIndex(i, ui[0])\n            u[i] = 0"},"outputs":[],"source":"def ContinuousFittedValueIteration(\n    plant,\n    plant_context,\n    value_mlp,\n    state_cost_function,\n    R_diag,\n    state_samples,\n    time_step=0.01,\n    discount_factor=1.0,\n    input_port_index=0,\n    lr=0.001,\n    minibatch=None,\n    epochs=1000,\n    optim_steps_per_epoch=25,\n    input_limits=None,\n):\n    input_port = plant.get_input_port(input_port_index)\n    num_states = plant.num_continuous_states()\n    num_inputs = input_port.size()\n    N = state_samples.shape[1]\n\n    # assert plant.ValidateContext(plant_context)  # TODO(russt): bind this\n    assert plant_context.has_only_continuous_state()\n    assert value_mlp.get_input_port().size() == num_states\n    assert value_mlp.layers()[-1] == 1\n    assert R_diag.shape == (num_inputs,)\n    assert state_samples.shape[0] == num_states\n    assert time_step > 0.0\n    assert discount_factor > 0.0 and discount_factor <= 1.0\n    if input_limits != None:\n        assert (\n            num_inputs == 1\n        ), \"Input limits are only supported for scalar inputs (for now)\"\n        assert len(input_limits) == 2\n\n    mlp_context = value_mlp.CreateDefaultContext()\n    generator = RandomGenerator(123)\n    value_mlp.SetRandomContext(mlp_context, generator)\n\n    state_cost = state_cost_function(state_samples)\n    state_dynamics_x = np.empty((N, num_states))\n    dstate_dynamics_du = [np.empty((num_states, N))] * num_inputs\n    Rinv = 1 / R_diag\n\n    state = plant_context.get_mutable_continuous_state_vector()\n\n    # Precompute dynamics and cost (TODO: parallelize this).\n    for i in range(N):\n        u = np.zeros(num_inputs)\n        input_port.FixValue(plant_context, u)\n        state.SetFromVector(state_samples[:, i])\n        state_dynamics_x[i] = plant.EvalTimeDerivatives(plant_context).CopyToVector()\n        for j in range(num_inputs):\n            u[j] = 1\n            input_port.FixValue(plant_context, u)\n            dstate_dynamics_du[j][:, i] = (\n                plant.EvalTimeDerivatives(plant_context).CopyToVector()\n                - state_dynamics_x[i]\n            )\n            u[j] = 0\n\n    optimizer = Adam(value_mlp.GetMutableParameters(mlp_context), lr=lr)\n\n    M = minibatch if minibatch else N\n    J = np.zeros((1, M))\n    Jnext = np.zeros((1, M))\n    Jd = np.zeros((1, M))\n    dJdX = np.asfortranarray(np.zeros((num_states, M)))\n    dloss_dparams = np.zeros(value_mlp.num_parameters())\n    last_loss = np.inf\n    for epoch in range(epochs if running_as_notebook else 2):\n        if minibatch:\n            batch = np.random.randint(0, N, minibatch)\n        else:\n            batch = range(N)\n        value_mlp.BatchOutput(mlp_context, state_samples[:, batch], J, dJdX)\n        Xnext = state_samples[:, batch] + time_step * state_dynamics_x[batch, :].T\n        G = state_cost[batch]\n        for i in range(num_inputs):\n            ui = -0.5 * Rinv[i] * np.sum(dstate_dynamics_du[i][:, batch] * dJdX, 0)\n            if input_limits != None:\n                ui = np.minimum(np.maximum(ui, input_limits[0]), input_limits[1])\n            G += R_diag[i] * ui**2\n            Xnext += time_step * dstate_dynamics_du[i][:, batch] * ui\n        value_mlp.BatchOutput(mlp_context, Xnext, Jnext)\n        Jd[:] = G * time_step + discount_factor * Jnext\n        for i in range(optim_steps_per_epoch if running_as_notebook else 2):\n            loss = value_mlp.BackpropagationMeanSquaredError(\n                mlp_context, state_samples[:, batch], Jd, dloss_dparams\n            )\n            optimizer.step(loss, dloss_dparams)\n        if not minibatch and np.linalg.norm(last_loss - loss) < 1e-8:\n            break\n        last_loss = loss\n        if epoch % 20 == 0:\n            clear_output(wait=True)\n            print(f\"epoch {epoch}: loss = {loss}\")\n\n    return mlp_context\n\n\nclass ContinuousFittedValueIterationPolicy(LeafSystem):\n    def __init__(\n        self,\n        plant,\n        value_mlp,\n        value_mlp_context,\n        R_diag,\n        input_port_index=0,\n        input_limits=None,\n    ):\n        LeafSystem.__init__(self)\n\n        num_plant_states = value_mlp.get_input_port().size()\n        self._plant = plant\n        self._plant_context = plant.CreateDefaultContext()\n\n        self.value_mlp = value_mlp\n        self.value_mlp_context = value_mlp_context\n        self.J = np.zeros((1, 1))\n        self.dJdX = np.asfortranarray(np.zeros((num_plant_states, 1)))\n\n        self.Rinv = 1 / R_diag\n        self.input_limits = input_limits\n        self.DeclareVectorInputPort(\"plant_state\", num_plant_states)\n        self._plant_input_port = self._plant.get_input_port(input_port_index)\n        self.DeclareVectorOutputPort(\n            \"output\", self._plant_input_port.size(), self.CalcOutput\n        )\n\n    def CalcOutput(self, context, output):\n        num_inputs = self._plant_input_port.size()\n        u = np.zeros(num_inputs)\n        plant_state = self.get_input_port().Eval(context)\n\n        self.value_mlp.BatchOutput(\n            self.value_mlp_context,\n            np.atleast_2d(plant_state).T,\n            self.J,\n            self.dJdX,\n        )\n\n        self._plant_context.SetContinuousState(plant_state)\n        self._plant_input_port.FixValue(self._plant_context, u)\n        state_dynamics_x = self._plant.EvalTimeDerivatives(\n            self._plant_context\n        ).CopyToVector()\n        for i in range(num_inputs):\n            u[i] = 1\n            self._plant_input_port.FixValue(self._plant_context, u)\n            dstate_dynamics_dui = (\n                self._plant.EvalTimeDerivatives(self._plant_context).CopyToVector()\n                - state_dynamics_x\n            )\n            ui = -0.5 * self.Rinv[i] * dstate_dynamics_dui.dot(self.dJdX)\n            if self.input_limits != None:\n                ui = np.minimum(\n                    np.maximum(ui, self.input_limits[0]), self.input_limits[1]\n                )\n            output.SetAtIndex(i, ui[0])\n            u[i] = 0"},{"block_group":"3945019535fe4b60999a1bd6098b35b6","cell_type":"markdown","execution_count":null,"metadata":{"cell_id":"836d425a39854149a998e2aeb87b0ff6","deepnote_block_group":"3945019535fe4b60999a1bd6098b35b6","deepnote_cell_type":"markdown","deepnote_sorting_key":"11","deepnote_source":"### Double Integrator"},"source":"### Double Integrator"},{"block_group":"5983696d6b304fc09f7d3d7942caf919","cell_type":"code","execution_count":null,"metadata":{"cell_id":"5b61b43e321646018e88948d2f99a7e6","deepnote_block_group":"5983696d6b304fc09f7d3d7942caf919","deepnote_cell_type":"code","deepnote_sorting_key":"12","deepnote_source":"A = np.array([[0.0, 1.0], [0.0, 0.0]])\nB = np.array([[0.0], [1.0]])\nplant = LinearSystem(A, B, np.empty((0, 2)), np.empty((0, 1)))\nplant_context = plant.CreateDefaultContext()\n\nQ = np.eye(2)\n\n\ndef quadratic_regulator_state_cost(x):\n    return (x * (Q @ x)).sum(axis=0)\n\n\nR_diag = np.array([1])\nR = np.eye(1)\ntime_step = 0.01\ndiscount_factor = 0.9\n\nvalue_mlp = MultilayerPerceptron(\n    [2, 16, 16, 1],\n    [\n        PerceptronActivationType.kReLU,\n        PerceptronActivationType.kReLU,\n        PerceptronActivationType.kIdentity,\n    ],\n)\n\nx1s = np.linspace(-5, 5, 31)\nx2s = np.linspace(-4, 4, 31)\nX1s, X2s = np.meshgrid(x1s, x2s, indexing=\"ij\")\nstate_samples = np.vstack((X1s.flatten(), X2s.flatten()))\nvalue_mlp_context = ContinuousFittedValueIteration(\n    plant,\n    plant_context,\n    value_mlp,\n    quadratic_regulator_state_cost,\n    R_diag,\n    state_samples,\n    time_step=time_step,\n    discount_factor=discount_factor,\n)\n\nmeshcat.Delete()\nmeshcat.ResetRenderMode()\nplot_and_compare(\n    value_mlp,\n    value_mlp_context,\n    quadratic_regulator_cost,\n    time_step,\n    discount_factor,\n)"},"outputs":[],"source":"A = np.array([[0.0, 1.0], [0.0, 0.0]])\nB = np.array([[0.0], [1.0]])\nplant = LinearSystem(A, B, np.empty((0, 2)), np.empty((0, 1)))\nplant_context = plant.CreateDefaultContext()\n\nQ = np.eye(2)\n\n\ndef quadratic_regulator_state_cost(x):\n    return (x * (Q @ x)).sum(axis=0)\n\n\nR_diag = np.array([1])\nR = np.eye(1)\ntime_step = 0.01\ndiscount_factor = 0.9\n\nvalue_mlp = MultilayerPerceptron(\n    [2, 16, 16, 1],\n    [\n        PerceptronActivationType.kReLU,\n        PerceptronActivationType.kReLU,\n        PerceptronActivationType.kIdentity,\n    ],\n)\n\nx1s = np.linspace(-5, 5, 31)\nx2s = np.linspace(-4, 4, 31)\nX1s, X2s = np.meshgrid(x1s, x2s, indexing=\"ij\")\nstate_samples = np.vstack((X1s.flatten(), X2s.flatten()))\nvalue_mlp_context = ContinuousFittedValueIteration(\n    plant,\n    plant_context,\n    value_mlp,\n    quadratic_regulator_state_cost,\n    R_diag,\n    state_samples,\n    time_step=time_step,\n    discount_factor=discount_factor,\n)\n\nmeshcat.Delete()\nmeshcat.ResetRenderMode()\nplot_and_compare(\n    value_mlp,\n    value_mlp_context,\n    quadratic_regulator_cost,\n    time_step,\n    discount_factor,\n)"},{"block_group":"4a11648e05804c809a92cb9d7c973251","cell_type":"markdown","execution_count":null,"metadata":{"cell_id":"b031c8892c54410ab8957beb7c32fb8c","deepnote_block_group":"4a11648e05804c809a92cb9d7c973251","deepnote_cell_type":"markdown","deepnote_sorting_key":"13","deepnote_source":"### Pendulum"},"source":"### Pendulum"},{"block_group":"716cd8a6d6c046ccba5f15e5c6a7f4a3","cell_type":"code","execution_count":null,"metadata":{"cell_id":"ec3382b1e08349cd869361eda93e42a7","deepnote_block_group":"716cd8a6d6c046ccba5f15e5c6a7f4a3","deepnote_cell_type":"code","deepnote_sorting_key":"14","deepnote_source":"plant = PendulumPlant()\nplant_context = plant.CreateDefaultContext()\n\nQ = np.diag([10, 1])\n\n\ndef quadratic_regulator_state_cost(x):\n    err = np.copy(x)\n    err[0] -= np.pi\n    return (err * (Q @ err)).sum(axis=0)\n\n\nR_diag = np.array([1])\nR = np.diag(R_diag)\n\nvalue_mlp = MultilayerPerceptron(\n    [True, False],\n    [100, 100, 1],\n    [\n        PerceptronActivationType.kReLU,\n        PerceptronActivationType.kReLU,\n        PerceptronActivationType.kIdentity,\n    ],\n)\n\nqs = np.linspace(0.0, 2.0 * np.pi, 51)\nqdots = np.linspace(-10.0, 10.0, 41)\nQs, Qdots = np.meshgrid(qs, qdots)\nstate_samples = np.vstack((Qs.flatten(), Qdots.flatten()))\ntime_step = 0.01\ndiscount_factor = 0.999\ntorque_limit = 3\nvalue_mlp_context = ContinuousFittedValueIteration(\n    plant,\n    plant_context,\n    value_mlp,\n    quadratic_regulator_state_cost,\n    R_diag,\n    state_samples,\n    time_step=time_step,\n    discount_factor=discount_factor,\n    minibatch=32,\n    lr=1e-5,\n    epochs=3000,\n    optim_steps_per_epoch=100,\n    input_limits=[-torque_limit, torque_limit],\n)\n\nJ = value_mlp.BatchOutput(value_mlp_context, state_samples)\nfig = plt.figure(1, figsize=(9, 4))\nax = fig.subplots()\nax.set_xlabel(\"q\")\nax.set_ylabel(\"qdot\")\nax.set_title(\"Cost-to-Go\")\nax.imshow(\n    J.reshape(qdots.size, qs.size),\n    cmap=cm.jet,\n    extent=(qs[0], qs[-1], qdots[-1], qdots[0]),\n)\nax.invert_yaxis()\nax.axis(\"auto\")\ndisplay(plt.show());"},"outputs":[],"source":"plant = PendulumPlant()\nplant_context = plant.CreateDefaultContext()\n\nQ = np.diag([10, 1])\n\n\ndef quadratic_regulator_state_cost(x):\n    err = np.copy(x)\n    err[0] -= np.pi\n    return (err * (Q @ err)).sum(axis=0)\n\n\nR_diag = np.array([1])\nR = np.diag(R_diag)\n\nvalue_mlp = MultilayerPerceptron(\n    [True, False],\n    [100, 100, 1],\n    [\n        PerceptronActivationType.kReLU,\n        PerceptronActivationType.kReLU,\n        PerceptronActivationType.kIdentity,\n    ],\n)\n\nqs = np.linspace(0.0, 2.0 * np.pi, 51)\nqdots = np.linspace(-10.0, 10.0, 41)\nQs, Qdots = np.meshgrid(qs, qdots)\nstate_samples = np.vstack((Qs.flatten(), Qdots.flatten()))\ntime_step = 0.01\ndiscount_factor = 0.999\ntorque_limit = 3\nvalue_mlp_context = ContinuousFittedValueIteration(\n    plant,\n    plant_context,\n    value_mlp,\n    quadratic_regulator_state_cost,\n    R_diag,\n    state_samples,\n    time_step=time_step,\n    discount_factor=discount_factor,\n    minibatch=32,\n    lr=1e-5,\n    epochs=3000,\n    optim_steps_per_epoch=100,\n    input_limits=[-torque_limit, torque_limit],\n)\n\nJ = value_mlp.BatchOutput(value_mlp_context, state_samples)\nfig = plt.figure(1, figsize=(9, 4))\nax = fig.subplots()\nax.set_xlabel(\"q\")\nax.set_ylabel(\"qdot\")\nax.set_title(\"Cost-to-Go\")\nax.imshow(\n    J.reshape(qdots.size, qs.size),\n    cmap=cm.jet,\n    extent=(qs[0], qs[-1], qdots[-1], qdots[0]),\n)\nax.invert_yaxis()\nax.axis(\"auto\")\ndisplay(plt.show());"},{"block_group":"dd81674df99a4aac83df2f5e8657e772","cell_type":"code","execution_count":null,"metadata":{"cell_id":"9b66de8bf5c948bc9938c5355cc742fa","deepnote_block_group":"dd81674df99a4aac83df2f5e8657e772","deepnote_cell_type":"code","deepnote_sorting_key":"15","deepnote_source":"def simulate(value_mlp, value_mlp_context, R_diag):\n    builder = DiagramBuilder()\n\n    scene_graph = builder.AddSystem(SceneGraph())\n    plant = builder.AddSystem(PendulumPlant())\n    PendulumGeometry.AddToBuilder(builder, plant.get_state_output_port(), scene_graph)\n\n    policy = builder.AddSystem(\n        ContinuousFittedValueIterationPolicy(\n            plant,\n            value_mlp,\n            value_mlp_context,\n            R_diag,\n            input_limits=[-torque_limit, torque_limit],\n        )\n    )\n    builder.Connect(plant.get_state_output_port(), policy.get_input_port())\n\n    zoh = builder.AddSystem(ZeroOrderHold(time_step, 1))\n    builder.Connect(policy.get_output_port(), zoh.get_input_port())\n    builder.Connect(zoh.get_output_port(), plant.get_input_port())\n\n    meshcat.Delete()\n    meshcat.Set2dRenderMode(\n        X_WC=RigidTransform(RotationMatrix.MakeZRotation(np.pi), [0, 1, 0])\n    )\n    vis = MeshcatVisualizer.AddToBuilder(builder, scene_graph, meshcat)\n\n    diagram = builder.Build()\n    simulator = Simulator(diagram)\n    context = simulator.get_mutable_context()\n    context.SetContinuousState([0.1, 0])\n    # simulator.set_target_realtime_rate(1.0 if running_as_notebook else 0.0)\n    vis.StartRecording(False)\n    simulator.AdvanceTo(4)\n    vis.PublishRecording()\n\n\nsimulate(value_mlp, value_mlp_context, R_diag)"},"outputs":[],"source":"def simulate(value_mlp, value_mlp_context, R_diag):\n    builder = DiagramBuilder()\n\n    scene_graph = builder.AddSystem(SceneGraph())\n    plant = builder.AddSystem(PendulumPlant())\n    PendulumGeometry.AddToBuilder(builder, plant.get_state_output_port(), scene_graph)\n\n    policy = builder.AddSystem(\n        ContinuousFittedValueIterationPolicy(\n            plant,\n            value_mlp,\n            value_mlp_context,\n            R_diag,\n            input_limits=[-torque_limit, torque_limit],\n        )\n    )\n    builder.Connect(plant.get_state_output_port(), policy.get_input_port())\n\n    zoh = builder.AddSystem(ZeroOrderHold(time_step, 1))\n    builder.Connect(policy.get_output_port(), zoh.get_input_port())\n    builder.Connect(zoh.get_output_port(), plant.get_input_port())\n\n    meshcat.Delete()\n    meshcat.Set2dRenderMode(\n        X_WC=RigidTransform(RotationMatrix.MakeZRotation(np.pi), [0, 1, 0])\n    )\n    vis = MeshcatVisualizer.AddToBuilder(builder, scene_graph, meshcat)\n\n    diagram = builder.Build()\n    simulator = Simulator(diagram)\n    context = simulator.get_mutable_context()\n    context.SetContinuousState([0.1, 0])\n    # simulator.set_target_realtime_rate(1.0 if running_as_notebook else 0.0)\n    vis.StartRecording(False)\n    simulator.AdvanceTo(4)\n    vis.PublishRecording()\n\n\nsimulate(value_mlp, value_mlp_context, R_diag)"},{"block_group":"65f770c49bb44815895747737e0188d8","cell_type":"markdown","execution_count":null,"metadata":{"cell_id":"6d68a20b8bbd4f85bd48a4bd71028c2e","deepnote_block_group":"65f770c49bb44815895747737e0188d8","deepnote_cell_type":"markdown","deepnote_sorting_key":"16","deepnote_source":"### Acrobot\n\nNote: I haven't quite finished this example yet!  (coming soon)"},"source":"### Acrobot\n\nNote: I haven't quite finished this example yet!  (coming soon)"},{"block_group":"4821fcf56aa143c1bb1a559791475b2e","cell_type":"code","execution_count":null,"metadata":{"cell_id":"1946b0b140cf4c74ad46dd9fa457858d","deepnote_block_group":"4821fcf56aa143c1bb1a559791475b2e","deepnote_cell_type":"code","deepnote_sorting_key":"17","deepnote_source":"plant = AcrobotPlant()\nplant_context = plant.CreateDefaultContext()\n\nQ = np.diag([10, 10, 1, 1])\n\n\ndef quadratic_regulator_state_cost(x):\n    err = np.copy(x)\n    err[0] -= np.pi\n    return (err * (Q @ err)).sum(axis=0)\n\n\nR_diag = np.array([1])\nR = np.diag(R_diag)\n\nvalue_mlp = MultilayerPerceptron(\n    [True, True, False, False],\n    [32, 32, 1],\n    [\n        PerceptronActivationType.kReLU,\n        PerceptronActivationType.kReLU,\n        PerceptronActivationType.kIdentity,\n    ],\n)\n\nq1s = np.linspace(0.0, 2.0 * np.pi, 21)\nq2s = np.linspace(0.0, 2.0 * np.pi, 21)\nq1dots = np.linspace(-10.0, 10.0, 11)\nq2dots = np.linspace(-10.0, 10.0, 11)\nQ1s, Q2s, Q1dots, Q2dots = np.meshgrid(q1s, q2s, q1dots, q2dots)\nstate_samples = np.vstack(\n    (Q1s.flatten(), Q2s.flatten(), Q1dots.flatten(), Q2dots.flatten())\n)\ntime_step = 0.01\ndiscount_factor = 0.95\nmlp_context = ContinuousFittedValueIteration(\n    plant,\n    plant_context,\n    value_mlp,\n    quadratic_regulator_state_cost,\n    R_diag,\n    state_samples,\n    time_step=time_step,\n    discount_factor=discount_factor,\n    lr=1e-5,\n    minibatch=500,\n)"},"outputs":[],"source":"plant = AcrobotPlant()\nplant_context = plant.CreateDefaultContext()\n\nQ = np.diag([10, 10, 1, 1])\n\n\ndef quadratic_regulator_state_cost(x):\n    err = np.copy(x)\n    err[0] -= np.pi\n    return (err * (Q @ err)).sum(axis=0)\n\n\nR_diag = np.array([1])\nR = np.diag(R_diag)\n\nvalue_mlp = MultilayerPerceptron(\n    [True, True, False, False],\n    [32, 32, 1],\n    [\n        PerceptronActivationType.kReLU,\n        PerceptronActivationType.kReLU,\n        PerceptronActivationType.kIdentity,\n    ],\n)\n\nq1s = np.linspace(0.0, 2.0 * np.pi, 21)\nq2s = np.linspace(0.0, 2.0 * np.pi, 21)\nq1dots = np.linspace(-10.0, 10.0, 11)\nq2dots = np.linspace(-10.0, 10.0, 11)\nQ1s, Q2s, Q1dots, Q2dots = np.meshgrid(q1s, q2s, q1dots, q2dots)\nstate_samples = np.vstack(\n    (Q1s.flatten(), Q2s.flatten(), Q1dots.flatten(), Q2dots.flatten())\n)\ntime_step = 0.01\ndiscount_factor = 0.95\nmlp_context = ContinuousFittedValueIteration(\n    plant,\n    plant_context,\n    value_mlp,\n    quadratic_regulator_state_cost,\n    R_diag,\n    state_samples,\n    time_step=time_step,\n    discount_factor=discount_factor,\n    lr=1e-5,\n    minibatch=500,\n)"}],
        "metadata": {"deepnote_notebook_id":"3711e4f1f4784c0bbb060e775bdb3ce7"},
        "nbformat": "4",
        "nbformat_minor": "0",
        "version": "0"
      }