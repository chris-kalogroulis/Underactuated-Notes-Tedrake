{"cells":[{"block_group":"5b8bc34f80b149e68aa963cb3021ed70","cell_type":"markdown","execution_count":null,"metadata":{"cell_id":"6adad26476fa47b19b01a7dd302720cf","deepnote_block_group":"5b8bc34f80b149e68aa963cb3021ed70","deepnote_cell_type":"markdown","deepnote_sorting_key":"0","deepnote_source":"# Direct Shooting vs Direct Transcription"},"source":"# Direct Shooting vs Direct Transcription"},{"block_group":"d2f7e2feb24545739276387de59c8add","cell_type":"code","execution_count":null,"metadata":{"cell_id":"b6b60fb66f654d9abb61ed67eb04d24c","deepnote_block_group":"d2f7e2feb24545739276387de59c8add","deepnote_cell_type":"code","deepnote_sorting_key":"1","deepnote_source":"import sys\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport scipy as sp\nfrom pydrake.all import DiscreteTimeLinearQuadraticRegulator\nfrom scipy.sparse.linalg import spsolve"},"outputs":[],"source":"import sys\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport scipy as sp\nfrom pydrake.all import DiscreteTimeLinearQuadraticRegulator\nfrom scipy.sparse.linalg import spsolve"},{"block_group":"320d61c960ad4fdba1a0fa320f7ba9f3","cell_type":"markdown","execution_count":null,"metadata":{"cell_id":"3feeb552406249e396a46382a6398c76","deepnote_block_group":"320d61c960ad4fdba1a0fa320f7ba9f3","deepnote_cell_type":"markdown","deepnote_sorting_key":"2","deepnote_source":"## Problem Description\n\nIn this notebook we compare two approaches to transcribe optimal control problems ([see here for more details](https://underactuated.mit.edu/trajopt.html#computational_considerations)):\n- **Direct transcription,** where in the optimal control problem both the inputs $\\mathbf{u}[n]$ and the states $\\mathbf{x}[n]$ are decision variables, and the dynamic equations $\\mathbf{x}[n+1] = \\mathbf{f}(\\mathbf{x}[n], \\mathbf{u}[n])$ are kept as constraints.\n- **Direct shooting,** where the states $\\mathbf{x}[n]$ are expressed as functions of the initial state $\\mathbf{x}[0]$ and the input sequence $(\\mathbf{u}[0], \\ldots, \\mathbf{u}[n-1])$, and eliminated from the optimization problem.\n\nAs discussed in the text, in some cases, direct transcription can be numerically more robust and also more efficient, even if direct shooting yields more compact optimization problem (less variables and constraints).\nIn this notebook we analyze the typical example in which this performance gap appears: optimal control of unstable systems with \"long\" time horizon.\n\nTo make the analysis as simple as possible, we will consider the finite-horizon LQR problem:\n$$\\begin{aligned} \\min & \\quad J = \\mathbf{x}^T[N] \\mathbf{Q}_N \\mathbf{x}[N]  + \\sum_{n=0}^{N-1} (\\mathbf{x}^T[n] \\mathbf{Q} \\mathbf{x}[n] + \\mathbf{u}^T[n] \\mathbf{R} \\mathbf{u}[n]) \\\\ \\text{subject to} & \\quad \\mathbf{x}[0] = \\mathbf{x}_0, \\\\ & \\quad \\mathbf{x}[n+1] = \\mathbf{A} \\mathbf{x}[n] + \\mathbf{B} \\mathbf{u}[n]. \\\\ \\end{aligned}$$\n\nwhere $\\mathbf{Q}_N \\succeq 0$, $\\mathbf{Q} \\succeq 0$, and $\\mathbf{R} \\succ 0$.\nOf course, numerical optimization is too big of a hammer for this problem: we can solve LQR in almost zero time by working on the Riccati equations!\nHowever, this problem setup is rich enough to exhibit all the characteristic failures that our direct methods might encounter when working with complex robots such as a humanoid.\n\nIn this notebook, you'll be asked to work on four pieces of code:\n- analyze the conditioning of the linear system of equations we get when using direct shooting,\n- implement part of the direct transcription method,\n- verify that the cost to go from direct trascription approaches the LQR cost to go as the time horizon grows,\n- analyze the conditioning of direct transcription,\n- implement the dynamic programming solution (a.k.a. Riccati recursion) for this problem.\n\nDon't worry if you aren't quite sure about the meaning of \"conditioning,\" you'll find all the details below!"},"source":"## Problem Description\n\nIn this notebook we compare two approaches to transcribe optimal control problems ([see here for more details](https://underactuated.mit.edu/trajopt.html#computational_considerations)):\n- **Direct transcription,** where in the optimal control problem both the inputs $\\mathbf{u}[n]$ and the states $\\mathbf{x}[n]$ are decision variables, and the dynamic equations $\\mathbf{x}[n+1] = \\mathbf{f}(\\mathbf{x}[n], \\mathbf{u}[n])$ are kept as constraints.\n- **Direct shooting,** where the states $\\mathbf{x}[n]$ are expressed as functions of the initial state $\\mathbf{x}[0]$ and the input sequence $(\\mathbf{u}[0], \\ldots, \\mathbf{u}[n-1])$, and eliminated from the optimization problem.\n\nAs discussed in the text, in some cases, direct transcription can be numerically more robust and also more efficient, even if direct shooting yields more compact optimization problem (less variables and constraints).\nIn this notebook we analyze the typical example in which this performance gap appears: optimal control of unstable systems with \"long\" time horizon.\n\nTo make the analysis as simple as possible, we will consider the finite-horizon LQR problem:\n$$\\begin{aligned} \\min & \\quad J = \\mathbf{x}^T[N] \\mathbf{Q}_N \\mathbf{x}[N]  + \\sum_{n=0}^{N-1} (\\mathbf{x}^T[n] \\mathbf{Q} \\mathbf{x}[n] + \\mathbf{u}^T[n] \\mathbf{R} \\mathbf{u}[n]) \\\\ \\text{subject to} & \\quad \\mathbf{x}[0] = \\mathbf{x}_0, \\\\ & \\quad \\mathbf{x}[n+1] = \\mathbf{A} \\mathbf{x}[n] + \\mathbf{B} \\mathbf{u}[n]. \\\\ \\end{aligned}$$\n\nwhere $\\mathbf{Q}_N \\succeq 0$, $\\mathbf{Q} \\succeq 0$, and $\\mathbf{R} \\succ 0$.\nOf course, numerical optimization is too big of a hammer for this problem: we can solve LQR in almost zero time by working on the Riccati equations!\nHowever, this problem setup is rich enough to exhibit all the characteristic failures that our direct methods might encounter when working with complex robots such as a humanoid.\n\nIn this notebook, you'll be asked to work on four pieces of code:\n- analyze the conditioning of the linear system of equations we get when using direct shooting,\n- implement part of the direct transcription method,\n- verify that the cost to go from direct trascription approaches the LQR cost to go as the time horizon grows,\n- analyze the conditioning of direct transcription,\n- implement the dynamic programming solution (a.k.a. Riccati recursion) for this problem.\n\nDon't worry if you aren't quite sure about the meaning of \"conditioning,\" you'll find all the details below!"},{"block_group":"89896057449c472ba89a3fbde0805996","cell_type":"markdown","execution_count":null,"metadata":{"cell_id":"020c814693104d8fab34702a96744ae0","deepnote_block_group":"89896057449c472ba89a3fbde0805996","deepnote_cell_type":"markdown","deepnote_sorting_key":"3","deepnote_source":"## Benchmark System\n\nJust to fix the ideas and plot some results, here we define a dynamical system which we'll use to test the functions we'll write in the notebook.\nIn particular, we use the discretized and linearized version of the inverted pendulum dynamics.\nAs we will see, unstable systems clearly highlight the advantages of direct transcription methods."},"source":"## Benchmark System\n\nJust to fix the ideas and plot some results, here we define a dynamical system which we'll use to test the functions we'll write in the notebook.\nIn particular, we use the discretized and linearized version of the inverted pendulum dynamics.\nAs we will see, unstable systems clearly highlight the advantages of direct transcription methods."},{"block_group":"f3a293f334ab410e99de9238304d5afd","cell_type":"code","execution_count":null,"metadata":{"cell_id":"667f0889050246cbb0bc84ed1d59d42f","deepnote_block_group":"f3a293f334ab410e99de9238304d5afd","deepnote_cell_type":"code","deepnote_sorting_key":"4","deepnote_source":"# time discretization step\nh = 0.5\n\n# linearized continuous time dynamics\n# (all physical parameters of the pendulum are set to one)\nAct = np.array([[0, 1], [1, 0]])\nBct = np.array([[0], [1]])\n\n# discretize using explicit Euler\n# x[n+1] = x[n] + h (Act x[n] + Bct u[n])\n#        = (I + h Act) x[n] + h Bct u[n]\nA = np.eye(Act.shape[0]) + h * Act\nB = h * Bct\n\n# objective function\nQ = np.array([[1, 0], [0, 0]])\nR = np.array([[1]])\nQN = np.array([[3, 0], [0, 2]])\n\n# initial state\nx0 = np.array([1, 1])"},"outputs":[],"source":"# time discretization step\nh = 0.5\n\n# linearized continuous time dynamics\n# (all physical parameters of the pendulum are set to one)\nAct = np.array([[0, 1], [1, 0]])\nBct = np.array([[0], [1]])\n\n# discretize using explicit Euler\n# x[n+1] = x[n] + h (Act x[n] + Bct u[n])\n#        = (I + h Act) x[n] + h Bct u[n]\nA = np.eye(Act.shape[0]) + h * Act\nB = h * Bct\n\n# objective function\nQ = np.array([[1, 0], [0, 0]])\nR = np.array([[1]])\nQN = np.array([[3, 0], [0, 2]])\n\n# initial state\nx0 = np.array([1, 1])"},{"block_group":"d394f9e976414f6594c6698d0ef87329","cell_type":"markdown","execution_count":null,"metadata":{"cell_id":"e3cb3e78d557407fb5bc3339b897f7d6","deepnote_block_group":"d394f9e976414f6594c6698d0ef87329","deepnote_cell_type":"markdown","deepnote_sorting_key":"5","deepnote_source":"As an asymptotic comparison for the different optimization problems we'll solve, we use the \"closed form\" solution of the infinite-horizon discrete-time Riccati equations.\nRecall that our LQR problem above has finite time horizon $N$, hence we expect its solution to converge to the infinite-horizon only for long-enough horizons $N$."},"source":"As an asymptotic comparison for the different optimization problems we'll solve, we use the \"closed form\" solution of the infinite-horizon discrete-time Riccati equations.\nRecall that our LQR problem above has finite time horizon $N$, hence we expect its solution to converge to the infinite-horizon only for long-enough horizons $N$."},{"block_group":"771de1e5d7ea4707a78dc093da93d708","cell_type":"code","execution_count":null,"metadata":{"cell_id":"862d77b5d787470faa016765a687726a","deepnote_block_group":"771de1e5d7ea4707a78dc093da93d708","deepnote_cell_type":"code","deepnote_sorting_key":"6","deepnote_source":"# optimal feedback gain and cost-to-go matrix\nK, S = DiscreteTimeLinearQuadraticRegulator(A, B, Q, R)\n\n# cost to go from state x0\nJ_star_inf = x0.dot(S).dot(x0)"},"outputs":[],"source":"# optimal feedback gain and cost-to-go matrix\nK, S = DiscreteTimeLinearQuadraticRegulator(A, B, Q, R)\n\n# cost to go from state x0\nJ_star_inf = x0.dot(S).dot(x0)"},{"block_group":"d936050a889a4ba2ac2ae57fa7b7d452","cell_type":"markdown","execution_count":null,"metadata":{"cell_id":"50d65ed20cdc4943a0e5fbd0bb7d8083","deepnote_block_group":"d936050a889a4ba2ac2ae57fa7b7d452","deepnote_cell_type":"markdown","deepnote_sorting_key":"7","deepnote_source":"## Direct shooting\n\nWe start with direct shooting.\n[In the lecture notes](https://underactuated.mit.edu/trajopt.html#direct_shooting), we have seen that the state $\\mathbf{x}[n]$ can be expressed as a function of the initial state $\\mathbf{x}[0]$ and the input sequence $\\mathbf{u}[0], \\ldots, \\mathbf{u}[n-1]$.\nWe derived the formula\n$$\\mathbf{x}[n] = \\mathbf{A}^n \\mathbf{x}_0 + \\sum_{k=0}^{n-1} \\mathbf{A}^{n-k-1} \\mathbf{B} \\mathbf{u}[k].$$\n\nDefining the vectors \n$$\n\\mathbb{x} =\n\\begin{bmatrix}\n\\mathbf{x}[1] \\\\\n\\vdots \\\\\n\\mathbf{x}[N]\n\\end{bmatrix},\n\\quad\n\\mathbb{u} =\n\\begin{bmatrix}\n\\mathbf{u}[0] \\\\\n\\vdots \\\\\n\\mathbf{u}[N-1]\n\\end{bmatrix},\n$$\nthe formula above can be written in matrix form as\n$$\n\\mathbb{x} =\n\\begin{bmatrix}\n\\mathbf{A} \\\\\n\\vdots \\\\\n\\mathbf{A}^N\n\\end{bmatrix}\n\\mathbf{x}_0 +\n\\begin{bmatrix}\n\\mathbf{B} & 0 & \\cdots & 0 \\\\\n\\mathbf{A B} & \\mathbf{B} & \\cdots & 0 \\\\\n\\vdots & \\vdots & \\ddots  & \\vdots \\\\\n\\mathbf{A}^{N-1} \\mathbf{B} & \\mathbf{A}^{N-2} \\mathbf{B} & \\cdots & \\mathbf{B} \\\\\n\\end{bmatrix}\n\\mathbb{u}.\n$$\nLet us call these two matrices $\\mathbb{A}$ and $\\mathbb{B}$ (in this notebook we'll use $\\mathbb{blackboard \\ bold}$ letters for block matrices), so that $\\mathbb{x} = \\mathbb{A} \\mathbf{x}_0 + \\mathbb{B} \\mathbb{u}$.\n\nIn the following cell we provide two efficient functions to construct $\\mathbb{A}$ and $\\mathbb{B}$.\nIn the code we denote, e.g., the matrix $\\mathbb{A}$ as `Ab`, where `b` stands for block matrix."},"source":"## Direct shooting\n\nWe start with direct shooting.\n[In the lecture notes](https://underactuated.mit.edu/trajopt.html#direct_shooting), we have seen that the state $\\mathbf{x}[n]$ can be expressed as a function of the initial state $\\mathbf{x}[0]$ and the input sequence $\\mathbf{u}[0], \\ldots, \\mathbf{u}[n-1]$.\nWe derived the formula\n$$\\mathbf{x}[n] = \\mathbf{A}^n \\mathbf{x}_0 + \\sum_{k=0}^{n-1} \\mathbf{A}^{n-k-1} \\mathbf{B} \\mathbf{u}[k].$$\n\nDefining the vectors \n$$\n\\mathbb{x} =\n\\begin{bmatrix}\n\\mathbf{x}[1] \\\\\n\\vdots \\\\\n\\mathbf{x}[N]\n\\end{bmatrix},\n\\quad\n\\mathbb{u} =\n\\begin{bmatrix}\n\\mathbf{u}[0] \\\\\n\\vdots \\\\\n\\mathbf{u}[N-1]\n\\end{bmatrix},\n$$\nthe formula above can be written in matrix form as\n$$\n\\mathbb{x} =\n\\begin{bmatrix}\n\\mathbf{A} \\\\\n\\vdots \\\\\n\\mathbf{A}^N\n\\end{bmatrix}\n\\mathbf{x}_0 +\n\\begin{bmatrix}\n\\mathbf{B} & 0 & \\cdots & 0 \\\\\n\\mathbf{A B} & \\mathbf{B} & \\cdots & 0 \\\\\n\\vdots & \\vdots & \\ddots  & \\vdots \\\\\n\\mathbf{A}^{N-1} \\mathbf{B} & \\mathbf{A}^{N-2} \\mathbf{B} & \\cdots & \\mathbf{B} \\\\\n\\end{bmatrix}\n\\mathbb{u}.\n$$\nLet us call these two matrices $\\mathbb{A}$ and $\\mathbb{B}$ (in this notebook we'll use $\\mathbb{blackboard \\ bold}$ letters for block matrices), so that $\\mathbb{x} = \\mathbb{A} \\mathbf{x}_0 + \\mathbb{B} \\mathbb{u}$.\n\nIn the following cell we provide two efficient functions to construct $\\mathbb{A}$ and $\\mathbb{B}$.\nIn the code we denote, e.g., the matrix $\\mathbb{A}$ as `Ab`, where `b` stands for block matrix."},{"block_group":"0e19c9546cd847329d65e184ba4ab5e7","cell_type":"code","execution_count":null,"metadata":{"cell_id":"cd5cc3b3f0644ea0aa26c717eade861c","deepnote_block_group":"0e19c9546cd847329d65e184ba4ab5e7","deepnote_cell_type":"code","deepnote_sorting_key":"8","deepnote_source":"# efficient computation of the matrix Ab\n\n\ndef get_Ab(A, N):\n    # Ab is defined only for N >= 1\n    assert N >= 1\n\n    # number of states\n    p = A.shape[0]\n\n    # initialize matrix with all zeros\n    Ab = np.zeros((p * N, p))\n\n    # put A matrix in top block\n    rows = slice(0, p)  # equivalent to :p\n    Ab[rows, :] = A\n\n    # loop over the block-rows\n    for n in range(1, N):\n        # move the row indices one block down\n        prev_rows = rows\n        rows = slice(\n            prev_rows.start + p, prev_rows.stop + p\n        )  # equivalent to n*p:(n+1)*p\n\n        # premultiply previous block by A\n        # place the result in this block\n        Ab[rows, :] = A.dot(Ab[prev_rows, :])\n\n    return Ab\n\n\n# efficient computation of the matrix Bb\ndef get_Bb(A, B, N):\n    # Bb is defined only for N >= 1\n    assert N >= 1\n\n    # number of states and inputs\n    p, q = B.shape\n\n    # initialize matrix with all zeros\n    Bb = np.zeros((p * N, q * N))\n\n    # put B matrix in top-left block\n    rows = slice(0, p)  # equivalent to :p\n    Bb[rows, :q] = B\n\n    # loop over the block-rows\n    for n in range(1, N):\n        # move the row indices one block down\n        prev_rows = rows\n        rows = slice(\n            prev_rows.start + p, prev_rows.stop + p\n        )  # equivalent to n*p:(n+1)*p\n\n        # premultiply first block from previous block-row by A\n        # place the result as first block of this block-row\n        Bb[rows, :q] = A.dot(Bb[prev_rows, :q])\n\n        # shift the rest of previous block-row one block forward and\n        # place it in the current block-row\n        Bb[rows, q : (n + 1) * q] = Bb[prev_rows, : n * q]\n\n    return Bb"},"outputs":[],"source":"# efficient computation of the matrix Ab\n\n\ndef get_Ab(A, N):\n    # Ab is defined only for N >= 1\n    assert N >= 1\n\n    # number of states\n    p = A.shape[0]\n\n    # initialize matrix with all zeros\n    Ab = np.zeros((p * N, p))\n\n    # put A matrix in top block\n    rows = slice(0, p)  # equivalent to :p\n    Ab[rows, :] = A\n\n    # loop over the block-rows\n    for n in range(1, N):\n        # move the row indices one block down\n        prev_rows = rows\n        rows = slice(\n            prev_rows.start + p, prev_rows.stop + p\n        )  # equivalent to n*p:(n+1)*p\n\n        # premultiply previous block by A\n        # place the result in this block\n        Ab[rows, :] = A.dot(Ab[prev_rows, :])\n\n    return Ab\n\n\n# efficient computation of the matrix Bb\ndef get_Bb(A, B, N):\n    # Bb is defined only for N >= 1\n    assert N >= 1\n\n    # number of states and inputs\n    p, q = B.shape\n\n    # initialize matrix with all zeros\n    Bb = np.zeros((p * N, q * N))\n\n    # put B matrix in top-left block\n    rows = slice(0, p)  # equivalent to :p\n    Bb[rows, :q] = B\n\n    # loop over the block-rows\n    for n in range(1, N):\n        # move the row indices one block down\n        prev_rows = rows\n        rows = slice(\n            prev_rows.start + p, prev_rows.stop + p\n        )  # equivalent to n*p:(n+1)*p\n\n        # premultiply first block from previous block-row by A\n        # place the result as first block of this block-row\n        Bb[rows, :q] = A.dot(Bb[prev_rows, :q])\n\n        # shift the rest of previous block-row one block forward and\n        # place it in the current block-row\n        Bb[rows, q : (n + 1) * q] = Bb[prev_rows, : n * q]\n\n    return Bb"},{"block_group":"ea266af0db304985b36299d2dfaf2aca","cell_type":"markdown","execution_count":null,"metadata":{"cell_id":"312d6dde6b52457c85ec511fbd5a2835","deepnote_block_group":"ea266af0db304985b36299d2dfaf2aca","deepnote_cell_type":"markdown","deepnote_sorting_key":"9","deepnote_source":"Let us write the LQR objective function in block-matrix form:\n$$\nJ =\n\\mathbf{x}_0^T \\mathbf{Q} \\mathbf{x}_0 +\n\\mathbb{x}^T\n\\begin{bmatrix}\n\\mathbf{Q} & \\cdots & 0 & 0 \\\\\n\\vdots & \\ddots & \\vdots & \\vdots \\\\\n0 & \\cdots  & \\mathbf{Q} & 0 \\\\\n0 & \\cdots  & 0 & \\mathbf{Q}_N \\\\\n\\end{bmatrix}\n\\mathbb{x} +\n\\mathbb{u}^T\n\\begin{bmatrix}\n\\mathbf{R} & \\cdots & 0 \\\\\n\\vdots & \\ddots  & \\vdots \\\\\n0 & \\cdots  & \\mathbf{R}\\\\\n\\end{bmatrix}\n\\mathbb{u}.\n$$\nWe denote the two block-diagonal matrices in the latter equation as $\\mathbb{Q}$ and $\\mathbb{R}$, so that $J = \\mathbf{x}_0^T \\mathbf{Q} \\mathbf{x}_0 + \\mathbb{x}^T \\mathbb{Q} \\mathbb{x} + \\mathbb{u}^T \\mathbb{R} \\mathbb{u}$.\n\nWe now use the relation $\\mathbb{x} = \\mathbb{A} \\mathbf{x}_0 + \\mathbb{B} \\mathbb{u}$.\nAfter a simple manipulation, we get\n$$\nJ = \\mathbf{x}_0^T (\\mathbf{Q} + \\mathbb{A}^T \\mathbb{Q} \\mathbb{A}) \\mathbf{x}_0 +\n2 \\mathbf{x}_0^T \\mathbb{A}^T \\mathbb{Q} \\mathbb{B} \\mathbb{u} +\n\\mathbb{u}^T (\\mathbb{R} + \\mathbb{B}^T \\mathbb{Q} \\mathbb{B}) \\mathbb{u}.\n$$\nWhere we used the fact that the matrices $\\mathbf{Q}$, $\\mathbf{R}$, and $\\mathbf{Q}_N$ are symmetric (hence, so are $\\mathbb{Q}$ and $\\mathbb{R}$).\n\nThe finite-time LQR problem has now become an unconstrained quadratic minimization problem.\nTo find the optimal control sequence $\\mathbb{u}^*$, we just set the derivative of $J$ with respect to $\\mathbb{u}$ to zero, and solve the resulting linear system.\nWe get\n$$\n2 \\mathbb{B}^T \\mathbb{Q} \\mathbb{A} \\mathbf{x}_0 +\n2 (\\mathbb{R} + \\mathbb{B}^T \\mathbb{Q} \\mathbb{B}) \\mathbb{u}\n= 0.\n$$\nLet use define $\\mathbb{H} = \\mathbb{R} + \\mathbb{B}^T \\mathbb{Q} \\mathbb{B}$.\nNote that this matrix is positive definite (hence invertible), since $\\mathbb{R} \\succ 0$ and $\\mathbb{B}^T \\mathbb{Q} \\mathbb{B} \\succeq 0$.\nThe optimal control sequence is then\n$$ \\mathbb{u}^* = - \\mathbb{H}^{-1} \\mathbb{B}^T \\mathbb{Q} \\mathbb{A} \\mathbf{x}_0.$$\nThe optimal cost $J^*$ can be derived by plugging the controls $\\mathbb{u}^*$ in the expression of $J$.\n\nIn the following cell we implemented these steps for you."},"source":"Let us write the LQR objective function in block-matrix form:\n$$\nJ =\n\\mathbf{x}_0^T \\mathbf{Q} \\mathbf{x}_0 +\n\\mathbb{x}^T\n\\begin{bmatrix}\n\\mathbf{Q} & \\cdots & 0 & 0 \\\\\n\\vdots & \\ddots & \\vdots & \\vdots \\\\\n0 & \\cdots  & \\mathbf{Q} & 0 \\\\\n0 & \\cdots  & 0 & \\mathbf{Q}_N \\\\\n\\end{bmatrix}\n\\mathbb{x} +\n\\mathbb{u}^T\n\\begin{bmatrix}\n\\mathbf{R} & \\cdots & 0 \\\\\n\\vdots & \\ddots  & \\vdots \\\\\n0 & \\cdots  & \\mathbf{R}\\\\\n\\end{bmatrix}\n\\mathbb{u}.\n$$\nWe denote the two block-diagonal matrices in the latter equation as $\\mathbb{Q}$ and $\\mathbb{R}$, so that $J = \\mathbf{x}_0^T \\mathbf{Q} \\mathbf{x}_0 + \\mathbb{x}^T \\mathbb{Q} \\mathbb{x} + \\mathbb{u}^T \\mathbb{R} \\mathbb{u}$.\n\nWe now use the relation $\\mathbb{x} = \\mathbb{A} \\mathbf{x}_0 + \\mathbb{B} \\mathbb{u}$.\nAfter a simple manipulation, we get\n$$\nJ = \\mathbf{x}_0^T (\\mathbf{Q} + \\mathbb{A}^T \\mathbb{Q} \\mathbb{A}) \\mathbf{x}_0 +\n2 \\mathbf{x}_0^T \\mathbb{A}^T \\mathbb{Q} \\mathbb{B} \\mathbb{u} +\n\\mathbb{u}^T (\\mathbb{R} + \\mathbb{B}^T \\mathbb{Q} \\mathbb{B}) \\mathbb{u}.\n$$\nWhere we used the fact that the matrices $\\mathbf{Q}$, $\\mathbf{R}$, and $\\mathbf{Q}_N$ are symmetric (hence, so are $\\mathbb{Q}$ and $\\mathbb{R}$).\n\nThe finite-time LQR problem has now become an unconstrained quadratic minimization problem.\nTo find the optimal control sequence $\\mathbb{u}^*$, we just set the derivative of $J$ with respect to $\\mathbb{u}$ to zero, and solve the resulting linear system.\nWe get\n$$\n2 \\mathbb{B}^T \\mathbb{Q} \\mathbb{A} \\mathbf{x}_0 +\n2 (\\mathbb{R} + \\mathbb{B}^T \\mathbb{Q} \\mathbb{B}) \\mathbb{u}\n= 0.\n$$\nLet use define $\\mathbb{H} = \\mathbb{R} + \\mathbb{B}^T \\mathbb{Q} \\mathbb{B}$.\nNote that this matrix is positive definite (hence invertible), since $\\mathbb{R} \\succ 0$ and $\\mathbb{B}^T \\mathbb{Q} \\mathbb{B} \\succeq 0$.\nThe optimal control sequence is then\n$$ \\mathbb{u}^* = - \\mathbb{H}^{-1} \\mathbb{B}^T \\mathbb{Q} \\mathbb{A} \\mathbf{x}_0.$$\nThe optimal cost $J^*$ can be derived by plugging the controls $\\mathbb{u}^*$ in the expression of $J$.\n\nIn the following cell we implemented these steps for you."},{"block_group":"3cc492a5d8d74ac18b3ef13b06662087","cell_type":"code","execution_count":null,"metadata":{"cell_id":"8b38f9d4da544d2ead8e5ad128ccced9","deepnote_block_group":"3cc492a5d8d74ac18b3ef13b06662087","deepnote_cell_type":"code","deepnote_sorting_key":"10","deepnote_source":"# function that given the system state x0 (together with:\n# the dynamical system matrices A, B; the objective weights\n# Q, R, QN; and the controller horizon N) returns the cost\n# to go of the finite-horizon LQR using direct shooting\n\n\ndef get_J_star_N_shooting(A, B, Q, R, QN, N, x0):\n    # condensed dynamic equations\n    Ab = get_Ab(A, N)\n    Bb = get_Bb(A, B, N)\n\n    # weight block matrices\n    Qb = sp.linalg.block_diag(*([Q] * (N - 1) + [QN]))\n    Rb = sp.linalg.block_diag(*([R] * N))\n    Hb = Rb + Bb.T.dot(Qb).dot(Bb)\n\n    # solve for the optimal ub\n    ub = np.linalg.solve(Hb, -Bb.T.dot(Qb).dot(Ab).dot(x0))\n\n    # plug optimal Ub in J to get the cost to go\n    J = (\n        x0.dot(Q + Ab.T.dot(Qb).dot(Ab)).dot(x0)\n        + 2 * x0.dot(Ab.T).dot(Qb).dot(Bb).dot(ub)\n        + ub.dot(Hb).dot(ub)\n    )\n\n    return J"},"outputs":[],"source":"# function that given the system state x0 (together with:\n# the dynamical system matrices A, B; the objective weights\n# Q, R, QN; and the controller horizon N) returns the cost\n# to go of the finite-horizon LQR using direct shooting\n\n\ndef get_J_star_N_shooting(A, B, Q, R, QN, N, x0):\n    # condensed dynamic equations\n    Ab = get_Ab(A, N)\n    Bb = get_Bb(A, B, N)\n\n    # weight block matrices\n    Qb = sp.linalg.block_diag(*([Q] * (N - 1) + [QN]))\n    Rb = sp.linalg.block_diag(*([R] * N))\n    Hb = Rb + Bb.T.dot(Qb).dot(Bb)\n\n    # solve for the optimal ub\n    ub = np.linalg.solve(Hb, -Bb.T.dot(Qb).dot(Ab).dot(x0))\n\n    # plug optimal Ub in J to get the cost to go\n    J = (\n        x0.dot(Q + Ab.T.dot(Qb).dot(Ab)).dot(x0)\n        + 2 * x0.dot(Ab.T).dot(Qb).dot(Bb).dot(ub)\n        + ub.dot(Hb).dot(ub)\n    )\n\n    return J"},{"block_group":"6a59945a5ab7454ca0dcce05f45b0fac","cell_type":"markdown","execution_count":null,"metadata":{"cell_id":"3797d0806e414a5f8f4dcedf1b4a823e","deepnote_block_group":"6a59945a5ab7454ca0dcce05f45b0fac","deepnote_cell_type":"markdown","deepnote_sorting_key":"11","deepnote_source":"We can now plot the cost to go of the finite-horizon LQR problem as a function of the horizon $N$, and compare it with the infinite-horizon cost to go."},"source":"We can now plot the cost to go of the finite-horizon LQR problem as a function of the horizon $N$, and compare it with the infinite-horizon cost to go."},{"block_group":"5edc480db05f48148771d81571ab8d9c","cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"cell_id":"211f13433afe4aaeb51bd464aaeeb311","deepnote_block_group":"5edc480db05f48148771d81571ab8d9c","deepnote_cell_type":"code","deepnote_sorting_key":"12","deepnote_source":"# function that plots the finite-horizon cost to go\n# as a function of the horizon length N\n# and compares it to the infinite-horizon solution\n# J_star_N is a list of floats: cost to go from N = 1 to N = N_max\n# J_star_inf is a float: infinite-horizon cost to go\n\n\ndef plot_J_star(J_star_N, J_star_inf):\n    # maximum length of the horizon\n    N_max = len(J_star_N)\n\n    # infinite-horizon cost to go\n    plt.plot(range(1, N_max + 1), [J_star_inf] * N_max, label=\"Infinite-horizon LQR\")\n\n    # finite-horizon cost to go\n    plt.plot(range(1, N_max + 1), J_star_N, label=\"Finite-horizon LQR\")\n\n    # misc settings\n    plt.xlim(0, N_max)\n    plt.xlabel(r\"Time horizon $N$\")\n    plt.ylabel(r\"Cost to go $J^*$\")\n    plt.grid(True)\n    plt.legend()\n\n\n# get cost to go as a function of N\nN_max = 45\nJ_star_N_shooting = [\n    get_J_star_N_shooting(A, B, Q, R, QN, N, x0) for N in range(1, N_max + 1)\n]\n\n# plot finite horizon vs infinite horizon\nplt.figure()\nplot_J_star(J_star_N_shooting, J_star_inf)"},"outputs":[],"source":"# function that plots the finite-horizon cost to go\n# as a function of the horizon length N\n# and compares it to the infinite-horizon solution\n# J_star_N is a list of floats: cost to go from N = 1 to N = N_max\n# J_star_inf is a float: infinite-horizon cost to go\n\n\ndef plot_J_star(J_star_N, J_star_inf):\n    # maximum length of the horizon\n    N_max = len(J_star_N)\n\n    # infinite-horizon cost to go\n    plt.plot(range(1, N_max + 1), [J_star_inf] * N_max, label=\"Infinite-horizon LQR\")\n\n    # finite-horizon cost to go\n    plt.plot(range(1, N_max + 1), J_star_N, label=\"Finite-horizon LQR\")\n\n    # misc settings\n    plt.xlim(0, N_max)\n    plt.xlabel(r\"Time horizon $N$\")\n    plt.ylabel(r\"Cost to go $J^*$\")\n    plt.grid(True)\n    plt.legend()\n\n\n# get cost to go as a function of N\nN_max = 45\nJ_star_N_shooting = [\n    get_J_star_N_shooting(A, B, Q, R, QN, N, x0) for N in range(1, N_max + 1)\n]\n\n# plot finite horizon vs infinite horizon\nplt.figure()\nplot_J_star(J_star_N_shooting, J_star_inf)"},{"block_group":"9e4f72aafdd344fdbbf65c1f2e2de056","cell_type":"markdown","execution_count":null,"metadata":{"cell_id":"9838df8ffe8e4bb8892b4962fe372342","deepnote_block_group":"9e4f72aafdd344fdbbf65c1f2e2de056","deepnote_cell_type":"markdown","deepnote_sorting_key":"13","deepnote_source":"The finite horizon solution already converges to the infinite-horizon one when $N$ is approximately equal to 5.\nBut when $N$ gets too large, the direct shooting approach runs into troubles!\n\nTo understand the reason for this behavior we analyze the [condition number](https://mathworld.wolfram.com/ConditionNumber.html) of $\\mathbb{H}$.\nFor a matrix $A$ the condition number $\\text{cond}(A)$ is defined as the ratio between the largest and the smallest singular values.\nWhen solving a linear system $Ax = b$, the larger the condition number, the more sensitive is the solution $x = A^{-1} b$ to small perturbations of the vector $b$.\nHence, if $\\text{cond}(A)$ is large, tiny numeric roundings in $b$ can be hugely amplified when solving for $x$.\n\nAnother interesting interpretation is the following. The quantity\n$$\n\\log_2 (\\text{cond}(A))\n$$\nis an estimate of how many bits are lost in solving a linear system $Ax = b$.\nFor example, if $\\text{cond}(A) = 2^{10}$ and $b$ is encoded in 64 bits, solving for $x$ we loose 10 of the 64 bits our machine is using!\n\nTo get the optimal controls via direct shooting, we invert the matrix $\\mathbb{H}$.\nIn the following cell, you are asked to analyze the condition number of $\\mathbb{H}$ as a function of the horizon length $N$.\nMore specifically, you must set the variable `lost_bits_shooting` to be a list with `N_max = 45` elements.\nFor `N` ranging from `1` to `N_max`, the `N`th entry in `lost_bits_shooting` must be logarithm in base 2 of the condition number of $\\mathbb{H}$ (`Hb` in the code) for a time horizon equal to `N`.\n\nP.s.: you might find the function [`numpy.linalg.cond`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.cond.html) useful here!"},"source":"The finite horizon solution already converges to the infinite-horizon one when $N$ is approximately equal to 5.\nBut when $N$ gets too large, the direct shooting approach runs into troubles!\n\nTo understand the reason for this behavior we analyze the [condition number](https://mathworld.wolfram.com/ConditionNumber.html) of $\\mathbb{H}$.\nFor a matrix $A$ the condition number $\\text{cond}(A)$ is defined as the ratio between the largest and the smallest singular values.\nWhen solving a linear system $Ax = b$, the larger the condition number, the more sensitive is the solution $x = A^{-1} b$ to small perturbations of the vector $b$.\nHence, if $\\text{cond}(A)$ is large, tiny numeric roundings in $b$ can be hugely amplified when solving for $x$.\n\nAnother interesting interpretation is the following. The quantity\n$$\n\\log_2 (\\text{cond}(A))\n$$\nis an estimate of how many bits are lost in solving a linear system $Ax = b$.\nFor example, if $\\text{cond}(A) = 2^{10}$ and $b$ is encoded in 64 bits, solving for $x$ we loose 10 of the 64 bits our machine is using!\n\nTo get the optimal controls via direct shooting, we invert the matrix $\\mathbb{H}$.\nIn the following cell, you are asked to analyze the condition number of $\\mathbb{H}$ as a function of the horizon length $N$.\nMore specifically, you must set the variable `lost_bits_shooting` to be a list with `N_max = 45` elements.\nFor `N` ranging from `1` to `N_max`, the `N`th entry in `lost_bits_shooting` must be logarithm in base 2 of the condition number of $\\mathbb{H}$ (`Hb` in the code) for a time horizon equal to `N`.\n\nP.s.: you might find the function [`numpy.linalg.cond`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.cond.html) useful here!"},{"block_group":"e465dc63cf0b486c8c42405c9c427892","cell_type":"code","execution_count":null,"metadata":{"cell_id":"52fddf2182504a7bba48b169d82ec480","deepnote_block_group":"e465dc63cf0b486c8c42405c9c427892","deepnote_cell_type":"code","deepnote_sorting_key":"14","deepnote_source":"# number of bits lost in the inversion of Hb\n# as a function of the time horizon N\nlost_bits_shooting = [np.nan for N in range(1, N_max + 1)]  # modify here"},"outputs":[],"source":"# number of bits lost in the inversion of Hb\n# as a function of the time horizon N\nlost_bits_shooting = [np.nan for N in range(1, N_max + 1)]  # modify here"},{"block_group":"4fa2640c23ca491aae7cd69e0e4728e6","cell_type":"markdown","execution_count":null,"metadata":{"cell_id":"071c76e5c469486ab126eaf9f526274e","deepnote_block_group":"4fa2640c23ca491aae7cd69e0e4728e6","deepnote_cell_type":"markdown","deepnote_sorting_key":"15","deepnote_source":"In the following cell we wrote a function to plot your results.\nDo you see anything alarming?\nWhich kind of law does this curve follow: constant, logarithmic, linear, polynomial, or exponential?"},"source":"In the following cell we wrote a function to plot your results.\nDo you see anything alarming?\nWhich kind of law does this curve follow: constant, logarithmic, linear, polynomial, or exponential?"},{"block_group":"53c3fe9875c64cfe9b7486a85ab35902","cell_type":"code","execution_count":null,"metadata":{"cell_id":"5538a991902842fb8496dcf3a5bf8d65","deepnote_block_group":"53c3fe9875c64cfe9b7486a85ab35902","deepnote_cell_type":"code","deepnote_sorting_key":"16","deepnote_source":"# plot the trend of the number of lost digits\n\n\ndef plot_lost_bits(lost_bits):\n    # plot number of bits in your machine\n    N_max = len(lost_bits)\n    plt.plot(\n        range(1, N_max + 1),\n        [np.log2(sys.maxsize) + 1] * N_max,  # extra bit due to the sign\n        label=\"Bits of your machine\",\n    )\n\n    # plot number of bits lost inverting Hb\n    plt.plot(\n        range(1, N_max + 1),\n        lost_bits,\n        label=r\"Bits lost inverting $\\mathbb{H}$\",\n    )\n\n    # misc settings\n    plt.xlim(0, N_max)\n    plt.xlabel(r\"Time horizon $N$\")\n    plt.ylabel(r\"Number of bits\")\n    plt.grid(True)\n    plt.legend()\n\n\n# plot your results\nplt.figure()\nplot_lost_bits(lost_bits_shooting)"},"outputs":[],"source":"# plot the trend of the number of lost digits\n\n\ndef plot_lost_bits(lost_bits):\n    # plot number of bits in your machine\n    N_max = len(lost_bits)\n    plt.plot(\n        range(1, N_max + 1),\n        [np.log2(sys.maxsize) + 1] * N_max,  # extra bit due to the sign\n        label=\"Bits of your machine\",\n    )\n\n    # plot number of bits lost inverting Hb\n    plt.plot(\n        range(1, N_max + 1),\n        lost_bits,\n        label=r\"Bits lost inverting $\\mathbb{H}$\",\n    )\n\n    # misc settings\n    plt.xlim(0, N_max)\n    plt.xlabel(r\"Time horizon $N$\")\n    plt.ylabel(r\"Number of bits\")\n    plt.grid(True)\n    plt.legend()\n\n\n# plot your results\nplt.figure()\nplot_lost_bits(lost_bits_shooting)"},{"block_group":"ffb3fba8a46944889d0ad1bfcd9a39ac","cell_type":"markdown","execution_count":null,"metadata":{"cell_id":"956accebc58e4a9f84485faf34f83aa9","deepnote_block_group":"ffb3fba8a46944889d0ad1bfcd9a39ac","deepnote_cell_type":"markdown","deepnote_sorting_key":"17","deepnote_source":"## Direct Transcription\n\nLet's now give a try to the direct transcription approach.\nIn these setting, our LQR problem is a quadratic optimization problem with equality constraints (i.e. the system dynamics).\nTo solve it, we use the technique of the [Lagrange multipliers](https://en.wikipedia.org/wiki/Lagrange_multiplier).\n\nWe define the Lagrange multipliers $\\lambda[0], \\ldots, \\lambda[N]$, and instead of enforcing the dynamics as constraints, we penalize it in the objective function.\nTo this end, we define the Lagrangian function\n$$\nL =\nJ +\n\\lambda^T[0] (\\mathbf{x}_0 - \\mathbf{x}[0]) +\n\\sum_{n=0}^{N-1}\n\\lambda^T[n+1](\\mathbf{A} \\mathbf{x}[n] + \\mathbf{B} \\mathbf{u}[n] - \\mathbf{x}[n+1]).\n$$\n\nThe optimal solution of the constrained optimization problem, is now recovered by minimizing the unconstrained Lagrangian function $L$ with respect to the states $\\mathbf{x}[n]$, the controls $\\mathbf{u}[n]$, and also the multipliers $\\lambda[n]$.\nThis can be done by simply setting the derivative of $L$ with respect to these variables to zero.\n\nHere are the resulting derivatives directly in matrix form.\nIf your eyes are trained in taking derivatives, you might quickly double-check this, if not, don't feel the need to derive this again...\n\n<!--\nAt the optimum, the gradient of $L$ with respect to $\\mathbf{x}[n]$, $\\mathbf{u}[n]$, and $\\lambda[n]$ must vanish.\nWe obtain the optimality conditions:\n- $\\nabla_{\\lambda[0]} L = \\mathbf{x}_0 - \\mathbf{x}[0]$,\n- $\\nabla_{\\lambda[n]} L = \\mathbf{A} \\mathbf{x}[n] + \\mathbf{B} \\mathbf{u}[n] - \\mathbf{x}[n+1] = 0$ for $n = 1, \\ldots, N$,\n- $\\nabla_{\\mathbf{x}[n]} L = 2 \\mathbf{Q} \\mathbf{x}[n] - \\lambda[n] + \\mathbf{A}^T \\lambda[n+1] = 0$ for $n = 0, \\ldots, N-1$,\n- $\\nabla_{\\mathbf{x}[N]} L = 2 \\mathbf{Q} \\mathbf{x}[N] - \\lambda[N] = 0$,\n- $\\nabla_{\\mathbf{u}[n]} L = 2 \\mathbf{R} \\mathbf{u}[n] + \\mathbf{B}^T \\lambda[n+1] = 0$ for $n = 0, \\ldots, N-1$.\n-->\n\n$$\n\\begin{bmatrix}\n\\nabla_{\\lambda[0]} L \\\\\n\\nabla_{\\mathbf{x}[0]} L \\\\\n\\nabla_{\\mathbf{u}[0]} L \\\\\n\\nabla_{\\lambda[1]} L \\\\\n\\nabla_{\\mathbf{x}[1]} L \\\\\n\\nabla_{\\mathbf{u}[1]} L \\\\\n\\vdots \\\\\n\\nabla_{\\mathbf{u}[N-1]} L \\\\\n\\nabla_{\\lambda[N]} L \\\\\n\\nabla_{\\mathbf{x}[N]} L \\\\\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n0 & -\\mathbf{I} & 0 & 0 & 0 & 0 & 0 & \\cdots & 0 & 0 & 0 & 0 \\\\\n-\\mathbf{I} & 2 \\mathbf{Q} & 0 & \\mathbf{A}^T & 0 & 0 & 0 & \\cdots & 0 & 0 & 0 & 0 \\\\\n0 & 0 & 2 \\mathbf{R} & \\mathbf{B}^T & 0 & 0 & 0 & \\cdots & 0 & 0 & 0 & 0 \\\\\n0 & \\mathbf{A} & \\mathbf{B} & 0 & -\\mathbf{I} & 0 & 0 & \\cdots & 0 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & -\\mathbf{I} & 2 \\mathbf{Q} & 0 & \\mathbf{A}^T & \\cdots & 0 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 0 & 0 & 2 \\mathbf{R} & \\mathbf{B}^T & \\cdots & 0 & 0 & 0 & 0 \\\\\n\\vdots & \\vdots & \\vdots & \\vdots & \\vdots & \\vdots & \\vdots & \\ddots & \\vdots & \\vdots & \\vdots & \\vdots \\\\\n0 & 0 & 0 & 0 & 0 & 0 & 0 & \\cdots & 0 & 2 \\mathbf{R} & \\mathbf{B}^T & 0 \\\\\n0 & 0 & 0 & 0 & 0 & 0 & 0 & \\cdots & \\mathbf{A} & \\mathbf{B} & 0 & -\\mathbf{I} \\\\\n0 & 0 & 0 & 0 & 0 & 0 & 0 & \\cdots & 0 & 0 & -\\mathbf{I} & 2 \\mathbf{Q}_N \\\\\n\\end{bmatrix}\n\\begin{bmatrix}\n\\lambda[0] \\\\\n\\mathbf{x}[0] \\\\\n\\mathbf{u}[0] \\\\\n\\lambda[1] \\\\\n\\mathbf{x}[1] \\\\\n\\mathbf{u}[1] \\\\\n\\lambda[2] \\\\\n\\vdots \\\\\n\\mathbf{x}[N-1] \\\\\n\\mathbf{u}[N-1] \\\\\n\\lambda[N] \\\\\n\\mathbf{x}[N] \\\\\n\\end{bmatrix}\n+\n\\begin{bmatrix}\n\\mathbf{x}_0 \\\\\n0 \\\\\n0 \\\\\n0 \\\\\n0 \\\\\n0 \\\\\n\\vdots \\\\\n0 \\\\\n0 \\\\\n0 \\\\\n\\end{bmatrix}\n= 0.\n$$\n\nIn the following, we will compactly refer to this big linear system as $\\mathbb{M} \\mathbb{z} = \\mathbb{x}_0$.\nWhere $\\mathbb{M}$ is the big matrix in the center, $\\mathbb{z}$ are the states, the controls, and the multipliers, and $\\mathbb{x}_0$ is the (negative) initial conditions concatenated with all the zeros."},"source":"## Direct Transcription\n\nLet's now give a try to the direct transcription approach.\nIn these setting, our LQR problem is a quadratic optimization problem with equality constraints (i.e. the system dynamics).\nTo solve it, we use the technique of the [Lagrange multipliers](https://en.wikipedia.org/wiki/Lagrange_multiplier).\n\nWe define the Lagrange multipliers $\\lambda[0], \\ldots, \\lambda[N]$, and instead of enforcing the dynamics as constraints, we penalize it in the objective function.\nTo this end, we define the Lagrangian function\n$$\nL =\nJ +\n\\lambda^T[0] (\\mathbf{x}_0 - \\mathbf{x}[0]) +\n\\sum_{n=0}^{N-1}\n\\lambda^T[n+1](\\mathbf{A} \\mathbf{x}[n] + \\mathbf{B} \\mathbf{u}[n] - \\mathbf{x}[n+1]).\n$$\n\nThe optimal solution of the constrained optimization problem, is now recovered by minimizing the unconstrained Lagrangian function $L$ with respect to the states $\\mathbf{x}[n]$, the controls $\\mathbf{u}[n]$, and also the multipliers $\\lambda[n]$.\nThis can be done by simply setting the derivative of $L$ with respect to these variables to zero.\n\nHere are the resulting derivatives directly in matrix form.\nIf your eyes are trained in taking derivatives, you might quickly double-check this, if not, don't feel the need to derive this again...\n\n<!--\nAt the optimum, the gradient of $L$ with respect to $\\mathbf{x}[n]$, $\\mathbf{u}[n]$, and $\\lambda[n]$ must vanish.\nWe obtain the optimality conditions:\n- $\\nabla_{\\lambda[0]} L = \\mathbf{x}_0 - \\mathbf{x}[0]$,\n- $\\nabla_{\\lambda[n]} L = \\mathbf{A} \\mathbf{x}[n] + \\mathbf{B} \\mathbf{u}[n] - \\mathbf{x}[n+1] = 0$ for $n = 1, \\ldots, N$,\n- $\\nabla_{\\mathbf{x}[n]} L = 2 \\mathbf{Q} \\mathbf{x}[n] - \\lambda[n] + \\mathbf{A}^T \\lambda[n+1] = 0$ for $n = 0, \\ldots, N-1$,\n- $\\nabla_{\\mathbf{x}[N]} L = 2 \\mathbf{Q} \\mathbf{x}[N] - \\lambda[N] = 0$,\n- $\\nabla_{\\mathbf{u}[n]} L = 2 \\mathbf{R} \\mathbf{u}[n] + \\mathbf{B}^T \\lambda[n+1] = 0$ for $n = 0, \\ldots, N-1$.\n-->\n\n$$\n\\begin{bmatrix}\n\\nabla_{\\lambda[0]} L \\\\\n\\nabla_{\\mathbf{x}[0]} L \\\\\n\\nabla_{\\mathbf{u}[0]} L \\\\\n\\nabla_{\\lambda[1]} L \\\\\n\\nabla_{\\mathbf{x}[1]} L \\\\\n\\nabla_{\\mathbf{u}[1]} L \\\\\n\\vdots \\\\\n\\nabla_{\\mathbf{u}[N-1]} L \\\\\n\\nabla_{\\lambda[N]} L \\\\\n\\nabla_{\\mathbf{x}[N]} L \\\\\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n0 & -\\mathbf{I} & 0 & 0 & 0 & 0 & 0 & \\cdots & 0 & 0 & 0 & 0 \\\\\n-\\mathbf{I} & 2 \\mathbf{Q} & 0 & \\mathbf{A}^T & 0 & 0 & 0 & \\cdots & 0 & 0 & 0 & 0 \\\\\n0 & 0 & 2 \\mathbf{R} & \\mathbf{B}^T & 0 & 0 & 0 & \\cdots & 0 & 0 & 0 & 0 \\\\\n0 & \\mathbf{A} & \\mathbf{B} & 0 & -\\mathbf{I} & 0 & 0 & \\cdots & 0 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & -\\mathbf{I} & 2 \\mathbf{Q} & 0 & \\mathbf{A}^T & \\cdots & 0 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 0 & 0 & 2 \\mathbf{R} & \\mathbf{B}^T & \\cdots & 0 & 0 & 0 & 0 \\\\\n\\vdots & \\vdots & \\vdots & \\vdots & \\vdots & \\vdots & \\vdots & \\ddots & \\vdots & \\vdots & \\vdots & \\vdots \\\\\n0 & 0 & 0 & 0 & 0 & 0 & 0 & \\cdots & 0 & 2 \\mathbf{R} & \\mathbf{B}^T & 0 \\\\\n0 & 0 & 0 & 0 & 0 & 0 & 0 & \\cdots & \\mathbf{A} & \\mathbf{B} & 0 & -\\mathbf{I} \\\\\n0 & 0 & 0 & 0 & 0 & 0 & 0 & \\cdots & 0 & 0 & -\\mathbf{I} & 2 \\mathbf{Q}_N \\\\\n\\end{bmatrix}\n\\begin{bmatrix}\n\\lambda[0] \\\\\n\\mathbf{x}[0] \\\\\n\\mathbf{u}[0] \\\\\n\\lambda[1] \\\\\n\\mathbf{x}[1] \\\\\n\\mathbf{u}[1] \\\\\n\\lambda[2] \\\\\n\\vdots \\\\\n\\mathbf{x}[N-1] \\\\\n\\mathbf{u}[N-1] \\\\\n\\lambda[N] \\\\\n\\mathbf{x}[N] \\\\\n\\end{bmatrix}\n+\n\\begin{bmatrix}\n\\mathbf{x}_0 \\\\\n0 \\\\\n0 \\\\\n0 \\\\\n0 \\\\\n0 \\\\\n\\vdots \\\\\n0 \\\\\n0 \\\\\n0 \\\\\n\\end{bmatrix}\n= 0.\n$$\n\nIn the following, we will compactly refer to this big linear system as $\\mathbb{M} \\mathbb{z} = \\mathbb{x}_0$.\nWhere $\\mathbb{M}$ is the big matrix in the center, $\\mathbb{z}$ are the states, the controls, and the multipliers, and $\\mathbb{x}_0$ is the (negative) initial conditions concatenated with all the zeros."},{"block_group":"801b5c2ca5b54212a45ae2c1dba1d006","cell_type":"markdown","execution_count":null,"metadata":{"cell_id":"276a919c4f4d4bb7b6e01a9e8d7c8be6","deepnote_block_group":"801b5c2ca5b54212a45ae2c1dba1d006","deepnote_cell_type":"markdown","deepnote_sorting_key":"18","deepnote_source":"**On the sparsity pattern of the matrix $\\mathbb{M}$**\n\nTake some seconds to analyze the structure of the matrix $\\mathbb{M}$.\n\nFirst note that the entries of this matrix are nonzero only nearby the diagonal (such a matrix is called \"[band sparse matrix](https://en.wikipedia.org/wiki/Band_matrix)\").\nWhen a matrix is [sparse](https://en.wikipedia.org/wiki/Sparse_matrix), it's always a good idea to take advantage of that: knowing ahead of time where the nonzero entries of our matrix are can save a lot of redundant computations (mostly multiplications by zero).\nIn the following code, we will exploit this structure in the solution of the linear system $\\mathbb{M} \\mathbb{z} = \\mathbb{x}_0$ by using [`scipy` sparse matrix package](https://docs.scipy.org/doc/scipy/reference/sparse.html).\n\nIn the next cell, you are asked to code the building block of the function we use to construct $\\mathbb{M}$.\nFor a generic time step $t$, consider the three equations: $\\nabla_{\\mathbf{x}[t]} L = 0$, $\\nabla_{\\mathbf{u}[t]} L = 0$, and $\\nabla_{\\lambda[t+1]} L = 0$.\nAnd note that these equations only depend on five variables: $\\lambda[t]$, $\\mathbf{x}[t]$, $\\mathbf{u}[t]$, $\\lambda[t+1]$, and $\\mathbf{x}[t+1]$.\n(To convince yourself, start by considering $t=0$.)\n\nThese three equations and five variables determine a precise block of the matrix $\\mathbb{M}$ which is repeated $N-1$ times along the diagonal.\nWrite a function named `diagonal_block_Mb` which constructs this block taking as inputs:\n- the linear system matrices $A$ and $B$,\n- the running cost weights $Q$ and $R$,\n\nTo do this, use the `scipy` block matrix function [`scipy.sparse.bmat`](https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.sparse.bmat.html)."},"source":"**On the sparsity pattern of the matrix $\\mathbb{M}$**\n\nTake some seconds to analyze the structure of the matrix $\\mathbb{M}$.\n\nFirst note that the entries of this matrix are nonzero only nearby the diagonal (such a matrix is called \"[band sparse matrix](https://en.wikipedia.org/wiki/Band_matrix)\").\nWhen a matrix is [sparse](https://en.wikipedia.org/wiki/Sparse_matrix), it's always a good idea to take advantage of that: knowing ahead of time where the nonzero entries of our matrix are can save a lot of redundant computations (mostly multiplications by zero).\nIn the following code, we will exploit this structure in the solution of the linear system $\\mathbb{M} \\mathbb{z} = \\mathbb{x}_0$ by using [`scipy` sparse matrix package](https://docs.scipy.org/doc/scipy/reference/sparse.html).\n\nIn the next cell, you are asked to code the building block of the function we use to construct $\\mathbb{M}$.\nFor a generic time step $t$, consider the three equations: $\\nabla_{\\mathbf{x}[t]} L = 0$, $\\nabla_{\\mathbf{u}[t]} L = 0$, and $\\nabla_{\\lambda[t+1]} L = 0$.\nAnd note that these equations only depend on five variables: $\\lambda[t]$, $\\mathbf{x}[t]$, $\\mathbf{u}[t]$, $\\lambda[t+1]$, and $\\mathbf{x}[t+1]$.\n(To convince yourself, start by considering $t=0$.)\n\nThese three equations and five variables determine a precise block of the matrix $\\mathbb{M}$ which is repeated $N-1$ times along the diagonal.\nWrite a function named `diagonal_block_Mb` which constructs this block taking as inputs:\n- the linear system matrices $A$ and $B$,\n- the running cost weights $Q$ and $R$,\n\nTo do this, use the `scipy` block matrix function [`scipy.sparse.bmat`](https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.sparse.bmat.html)."},{"block_group":"229b3af025d244a0a784bbea21d94fbf","cell_type":"code","execution_count":null,"metadata":{"cell_id":"ad1d8b8a48764164b25d4ea16353d818","deepnote_block_group":"229b3af025d244a0a784bbea21d94fbf","deepnote_cell_type":"code","deepnote_sorting_key":"19","deepnote_source":"# function that given the dynamical system matrices\n# A and B, and the weights Q and R, returns the\n# reapeated block on the diagonal of Mb\n\n\ndef Mb_diagonal_block(A, B, Q, R):\n    # number of states and inputs of the linear dynamics\n    p, q = B.shape\n\n    # block matrix\n    Ip = sp.sparse.eye(p)  # modify here\n    Iq = sp.sparse.eye(q)  # modify here\n    my_block = sp.sparse.bmat(\n        [  # modify here\n            [Ip, None, None, Ip, None],  # modify here\n            [None, None, Iq, None, None],  # modify here\n            [None, Ip, None, None, Ip],  # modify here\n        ]\n    )\n\n    return my_block"},"outputs":[],"source":"# function that given the dynamical system matrices\n# A and B, and the weights Q and R, returns the\n# reapeated block on the diagonal of Mb\n\n\ndef Mb_diagonal_block(A, B, Q, R):\n    # number of states and inputs of the linear dynamics\n    p, q = B.shape\n\n    # block matrix\n    Ip = sp.sparse.eye(p)  # modify here\n    Iq = sp.sparse.eye(q)  # modify here\n    my_block = sp.sparse.bmat(\n        [  # modify here\n            [Ip, None, None, Ip, None],  # modify here\n            [None, None, Iq, None, None],  # modify here\n            [None, Ip, None, None, Ip],  # modify here\n        ]\n    )\n\n    return my_block"},{"block_group":"c733600b4a8f4e05ba3a60c0e1856d46","cell_type":"markdown","execution_count":null,"metadata":{"cell_id":"ab578c9539fb4059a02b810a08258759","deepnote_block_group":"c733600b4a8f4e05ba3a60c0e1856d46","deepnote_cell_type":"markdown","deepnote_sorting_key":"20","deepnote_source":"Now we fill the matrix $\\mathbb{M}$ with the code you wrote.\nWe already took care of the first row (initial conditions) and the final row (terminal cost).\nFor the rest we just copy and paste the matrix you wrote along the diagonal of $\\mathbb{M}$.\n\nHere are two efficient functions to derive $\\mathbb{M}$ and $\\mathbb{x}_0$ in [sparse form](https://en.wikipedia.org/wiki/Sparse_matrix)."},"source":"Now we fill the matrix $\\mathbb{M}$ with the code you wrote.\nWe already took care of the first row (initial conditions) and the final row (terminal cost).\nFor the rest we just copy and paste the matrix you wrote along the diagonal of $\\mathbb{M}$.\n\nHere are two efficient functions to derive $\\mathbb{M}$ and $\\mathbb{x}_0$ in [sparse form](https://en.wikipedia.org/wiki/Sparse_matrix)."},{"block_group":"c034280775cf461cb539dea1c7e91419","cell_type":"code","execution_count":null,"metadata":{"cell_id":"0869a11d06de4a1a8ffb70adad86b0f0","deepnote_block_group":"c034280775cf461cb539dea1c7e91419","deepnote_cell_type":"code","deepnote_sorting_key":"21","deepnote_source":"# efficient computation of the matrix Mb\n# uses scipy sparse matrices:\n# https://docs.scipy.org/doc/scipy/reference/sparse.html\n\n\ndef get_Mb(A, B, Q, R, QN, N):\n    # number of states and inputs\n    p, q = B.shape\n\n    # number of optimization variables in zb\n    n_zb = 2 * (N + 1) * p + N * q\n\n    # initialize with empty sparse matrix\n    # (lil stands for list of lists)\n    Mb = sp.sparse.lil_matrix((n_zb, n_zb))\n\n    # first block-row (initial conditions)\n    Mb[:p, p : 2 * p] = -sp.sparse.eye(p)\n\n    # use the function you wrote to get the diagonal block\n    Mb_block = Mb_diagonal_block(A, B, Q, R)\n\n    # initialize indices for the insertion of the blocks\n    rows = slice(p, Mb_block.shape[0] + p)\n    cols = slice(0, Mb_block.shape[1])\n    step = 2 * p + q\n\n    # loop overt the diagonal and paste the Mb_block\n    # in the appropriate spots\n    for n in range(N):\n        Mb[rows, cols] = Mb_block\n        rows = slice(rows.start + step, rows.stop + step)\n        cols = slice(cols.start + step, cols.stop + step)\n\n    # last block-row (terminal state)\n    Mb[-p:, -2 * p : -p] = -sp.sparse.eye(p)\n    Mb[-p:, -p:] = 2 * QN\n\n    # convert matrix to scipy sparse csc matrix\n    # (csc stands for compressed sparse column)\n    return Mb.tocsc()\n\n\n# efficient computation of the vector xb0\n# p is the number of system states and\n# p is the number of system inputs\ndef get_xb0(x0, p, q, N):\n    # indices of the nonzero elements in xb0\n    rows = range(p)\n    cols = [0] * p\n    sparsity = (rows, cols)\n\n    # overall shape of xb0\n    # (total number of rows, number of cols = 1)\n    n_zb = 2 * (N + 1) * p + N * q\n    shape = (n_zb, 1)\n\n    # xb0 in sparse form\n    xb0 = sp.sparse.csc_matrix((x0, sparsity), shape=shape)\n\n    return xb0"},"outputs":[],"source":"# efficient computation of the matrix Mb\n# uses scipy sparse matrices:\n# https://docs.scipy.org/doc/scipy/reference/sparse.html\n\n\ndef get_Mb(A, B, Q, R, QN, N):\n    # number of states and inputs\n    p, q = B.shape\n\n    # number of optimization variables in zb\n    n_zb = 2 * (N + 1) * p + N * q\n\n    # initialize with empty sparse matrix\n    # (lil stands for list of lists)\n    Mb = sp.sparse.lil_matrix((n_zb, n_zb))\n\n    # first block-row (initial conditions)\n    Mb[:p, p : 2 * p] = -sp.sparse.eye(p)\n\n    # use the function you wrote to get the diagonal block\n    Mb_block = Mb_diagonal_block(A, B, Q, R)\n\n    # initialize indices for the insertion of the blocks\n    rows = slice(p, Mb_block.shape[0] + p)\n    cols = slice(0, Mb_block.shape[1])\n    step = 2 * p + q\n\n    # loop overt the diagonal and paste the Mb_block\n    # in the appropriate spots\n    for n in range(N):\n        Mb[rows, cols] = Mb_block\n        rows = slice(rows.start + step, rows.stop + step)\n        cols = slice(cols.start + step, cols.stop + step)\n\n    # last block-row (terminal state)\n    Mb[-p:, -2 * p : -p] = -sp.sparse.eye(p)\n    Mb[-p:, -p:] = 2 * QN\n\n    # convert matrix to scipy sparse csc matrix\n    # (csc stands for compressed sparse column)\n    return Mb.tocsc()\n\n\n# efficient computation of the vector xb0\n# p is the number of system states and\n# p is the number of system inputs\ndef get_xb0(x0, p, q, N):\n    # indices of the nonzero elements in xb0\n    rows = range(p)\n    cols = [0] * p\n    sparsity = (rows, cols)\n\n    # overall shape of xb0\n    # (total number of rows, number of cols = 1)\n    n_zb = 2 * (N + 1) * p + N * q\n    shape = (n_zb, 1)\n\n    # xb0 in sparse form\n    xb0 = sp.sparse.csc_matrix((x0, sparsity), shape=shape)\n\n    return xb0"},{"block_group":"d580129650094e9c9bd654a62c6f92c2","cell_type":"markdown","execution_count":null,"metadata":{"cell_id":"0ab31b1e86064200bc1d4541a3057697","deepnote_block_group":"d580129650094e9c9bd654a62c6f92c2","deepnote_cell_type":"markdown","deepnote_sorting_key":"22","deepnote_source":"Here is a nice `matplotlib` function that allows you to \"spy\" inside a matrix and look at its structure (a.k.a. the sparsity pattern)."},"source":"Here is a nice `matplotlib` function that allows you to \"spy\" inside a matrix and look at its structure (a.k.a. the sparsity pattern)."},{"block_group":"a46ab503945d4d1c999ffe4653455a6a","cell_type":"code","execution_count":null,"metadata":{"cell_id":"6255a91de7e941bb963a6c509803d199","deepnote_block_group":"a46ab503945d4d1c999ffe4653455a6a","deepnote_cell_type":"code","deepnote_sorting_key":"23","deepnote_source":"# arbitrary short time horizon\nN = 5\n\n# plot the sparsity pattern of Mb\nplt.figure()\nplt.spy(get_Mb(A, B, Q, R, QN, N))"},"outputs":[],"source":"# arbitrary short time horizon\nN = 5\n\n# plot the sparsity pattern of Mb\nplt.figure()\nplt.spy(get_Mb(A, B, Q, R, QN, N))"},{"block_group":"e40418d7a67646349634ca1201bf151b","cell_type":"markdown","execution_count":null,"metadata":{"cell_id":"94cebc6752af407bba1805aa70657144","deepnote_block_group":"e40418d7a67646349634ca1201bf151b","deepnote_cell_type":"markdown","deepnote_sorting_key":"24","deepnote_source":"To simplify your upcoming work, we provided you:\n- Two functions to extract the states $\\mathbb{x}$ and the controls $\\mathbb{u}$ from the unknowns $\\mathbb{z}$ of the linear system $\\mathbb{M} \\mathbb{z} = \\mathbb{x}_0$.\n- A function to evaluate $J$ given $\\mathbb{x}$ and $\\mathbb{u}$."},"source":"To simplify your upcoming work, we provided you:\n- Two functions to extract the states $\\mathbb{x}$ and the controls $\\mathbb{u}$ from the unknowns $\\mathbb{z}$ of the linear system $\\mathbb{M} \\mathbb{z} = \\mathbb{x}_0$.\n- A function to evaluate $J$ given $\\mathbb{x}$ and $\\mathbb{u}$."},{"block_group":"ece501ffeea849d88741c0e5cd6fa8fa","cell_type":"code","execution_count":null,"metadata":{"cell_id":"f29b64f546154d659a10419964c5b7f0","deepnote_block_group":"ece501ffeea849d88741c0e5cd6fa8fa","deepnote_cell_type":"code","deepnote_sorting_key":"25","deepnote_source":"# function that extracts the vector\n# xb = (x[0], ..., x[N]) from zb\n\n\ndef extract_xb_from_zb(zb, p, q, N):\n    # index of the first element of x[0] in the vector zb\n    start = p\n\n    # distance between x[n] and x[n+1] in the vector zb\n    step = 2 * p + q\n\n    # extract states\n    xb_indices = [start + step * n + i for n in range(N + 1) for i in range(p)]\n    xb = zb[xb_indices]\n\n    return xb\n\n\n# function that extracts the vector\n# ub = (u[0], ..., u[N-1]) from zb\ndef extract_ub_from_zb(zb, p, q, N):\n    # index of the first element of u[0] in the vector zb\n    start = 2 * p\n\n    # distance between u[n] and u[n+1] in the vector zb\n    step = 2 * p + q\n\n    # extract controls\n    ub_indices = [start + step * n + i for n in range(N) for i in range(q)]\n    ub = zb[ub_indices]\n\n    return ub\n\n\n# function that evaluates the objective J\n# given the block vectors xb and ub\ndef evaluate_J(xb, ub, Q, R, QN, N):\n    # block diagonal cost matrices\n    # (Qb has one extra block for the initial state here)\n    Qb = sp.sparse.block_diag(([Q] * N + [QN]))\n    Rb = sp.sparse.block_diag(([R] * N))\n\n    # compute value function\n    J = xb.dot(Qb.dot(xb)) + ub.dot(Rb.dot(ub))\n\n    return J"},"outputs":[],"source":"# function that extracts the vector\n# xb = (x[0], ..., x[N]) from zb\n\n\ndef extract_xb_from_zb(zb, p, q, N):\n    # index of the first element of x[0] in the vector zb\n    start = p\n\n    # distance between x[n] and x[n+1] in the vector zb\n    step = 2 * p + q\n\n    # extract states\n    xb_indices = [start + step * n + i for n in range(N + 1) for i in range(p)]\n    xb = zb[xb_indices]\n\n    return xb\n\n\n# function that extracts the vector\n# ub = (u[0], ..., u[N-1]) from zb\ndef extract_ub_from_zb(zb, p, q, N):\n    # index of the first element of u[0] in the vector zb\n    start = 2 * p\n\n    # distance between u[n] and u[n+1] in the vector zb\n    step = 2 * p + q\n\n    # extract controls\n    ub_indices = [start + step * n + i for n in range(N) for i in range(q)]\n    ub = zb[ub_indices]\n\n    return ub\n\n\n# function that evaluates the objective J\n# given the block vectors xb and ub\ndef evaluate_J(xb, ub, Q, R, QN, N):\n    # block diagonal cost matrices\n    # (Qb has one extra block for the initial state here)\n    Qb = sp.sparse.block_diag(([Q] * N + [QN]))\n    Rb = sp.sparse.block_diag(([R] * N))\n\n    # compute value function\n    J = xb.dot(Qb.dot(xb)) + ub.dot(Rb.dot(ub))\n\n    return J"},{"block_group":"012675d5157d46ffa6c0dcef37c51a06","cell_type":"markdown","execution_count":null,"metadata":{"cell_id":"ac8c9f6dcee34cf5aea27db44a18d4f1","deepnote_block_group":"012675d5157d46ffa6c0dcef37c51a06","deepnote_cell_type":"markdown","deepnote_sorting_key":"26","deepnote_source":"Now it's your turn again.\nFor direct shooting, we have defined above the function `get_J_star_N_shooting(A, B, Q, R, QN, N, x0)`, which given the LQR data and the initial state, returns the cost to go for the finite-horizon problem using direct shooting.\n\nIn the following cell you're asked to write the analogous function for the direct transcription method.\nThe function must have the name `get_J_star_N_transcription` and its arguments must be `A, B, Q, R, QN, N, x0`.\nThe steps in this function must be:\n- get the matrix $\\mathbb{M}$ and the vector $\\mathbb{x}_0$,\n- solve the linear system $\\mathbb{M} \\mathbb{z} = \\mathbb{x}_0$ for $\\mathbb{z}^*$,\n- extract $\\mathbb{x}^*$ and $\\mathbb{u}^*$ from $\\mathbb{z}^*$,\n- plug $\\mathbb{x}^*$ and $\\mathbb{u}^*$ in the expression for $J$.\n\nTo solve the sparse linear system $\\mathbb{M} \\mathbb{z} = \\mathbb{x}_0$, use the `scipy` function [`scipy.sparse.linalg.spsolve`](https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.sparse.linalg.spsolve.html), which is already imported as `spsolve`."},"source":"Now it's your turn again.\nFor direct shooting, we have defined above the function `get_J_star_N_shooting(A, B, Q, R, QN, N, x0)`, which given the LQR data and the initial state, returns the cost to go for the finite-horizon problem using direct shooting.\n\nIn the following cell you're asked to write the analogous function for the direct transcription method.\nThe function must have the name `get_J_star_N_transcription` and its arguments must be `A, B, Q, R, QN, N, x0`.\nThe steps in this function must be:\n- get the matrix $\\mathbb{M}$ and the vector $\\mathbb{x}_0$,\n- solve the linear system $\\mathbb{M} \\mathbb{z} = \\mathbb{x}_0$ for $\\mathbb{z}^*$,\n- extract $\\mathbb{x}^*$ and $\\mathbb{u}^*$ from $\\mathbb{z}^*$,\n- plug $\\mathbb{x}^*$ and $\\mathbb{u}^*$ in the expression for $J$.\n\nTo solve the sparse linear system $\\mathbb{M} \\mathbb{z} = \\mathbb{x}_0$, use the `scipy` function [`scipy.sparse.linalg.spsolve`](https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.sparse.linalg.spsolve.html), which is already imported as `spsolve`."},{"block_group":"673e553e01ba426f9c1eaf780058d394","cell_type":"code","execution_count":null,"metadata":{"cell_id":"785c1bf4fd034bc0a40783a282e5ffeb","deepnote_block_group":"673e553e01ba426f9c1eaf780058d394","deepnote_cell_type":"code","deepnote_sorting_key":"27","deepnote_source":"# function that given the system state x0 (together with:\n# the dynamical system matrices A, B; the objective weights\n# Q, R, QN; and the controller horizon N) returns the cost\n# to go of the finite-horizon LQR using direct transcription\n\n\ndef get_J_star_N_transcription(A, B, Q, R, QN, N, x0):\n    return np.nan  # modify here"},"outputs":[],"source":"# function that given the system state x0 (together with:\n# the dynamical system matrices A, B; the objective weights\n# Q, R, QN; and the controller horizon N) returns the cost\n# to go of the finite-horizon LQR using direct transcription\n\n\ndef get_J_star_N_transcription(A, B, Q, R, QN, N, x0):\n    return np.nan  # modify here"},{"block_group":"5cd5d5f921974bd590f1998ac5deefbb","cell_type":"markdown","execution_count":null,"metadata":{"cell_id":"fa8f97e654834d6983bfbec30e5efe28","deepnote_block_group":"5cd5d5f921974bd590f1998ac5deefbb","deepnote_cell_type":"markdown","deepnote_sorting_key":"28","deepnote_source":"Here is the same plot we had for direct shooting. Does it look better than the direct-shooting one?"},"source":"Here is the same plot we had for direct shooting. Does it look better than the direct-shooting one?"},{"block_group":"5e885cf8a929424a93d2b580c871eac6","cell_type":"code","execution_count":null,"metadata":{"cell_id":"823d4a3a066d44b19f70360d3e582dc3","deepnote_block_group":"5e885cf8a929424a93d2b580c871eac6","deepnote_cell_type":"code","deepnote_sorting_key":"29","deepnote_source":"# get cost to go as a function of N\nN_max = 45\nJ_star_N_transcription = [\n    get_J_star_N_transcription(A, B, Q, R, QN, N, x0) for N in range(1, N_max + 1)\n]\n\n# plot finite horizon vs infinite horizon\nplt.figure()\nplot_J_star(J_star_N_transcription, J_star_inf)"},"outputs":[],"source":"# get cost to go as a function of N\nN_max = 45\nJ_star_N_transcription = [\n    get_J_star_N_transcription(A, B, Q, R, QN, N, x0) for N in range(1, N_max + 1)\n]\n\n# plot finite horizon vs infinite horizon\nplt.figure()\nplot_J_star(J_star_N_transcription, J_star_inf)"},{"block_group":"83f48942fb7c4fc99e41729369ced231","cell_type":"markdown","execution_count":null,"metadata":{"cell_id":"db6fe1d8061f429c863dd157af01e32b","deepnote_block_group":"83f48942fb7c4fc99e41729369ced231","deepnote_cell_type":"markdown","deepnote_sorting_key":"30","deepnote_source":"It's time to replicate the plot of the lost digits in the case of direct transcription.\nNow we look at the condition number of $\\mathbb{M}$.\n\nDefine a list with name `lost_bits_transcription` which contains `N_max = 100` elements.\nFor `N` ranging from `1` to `N_max`, the `N`th entry in `lost_bits_transcription` must be logarithm in base 2 of the condition number of $\\mathbb{M}$ (`Mb` in the code) for a time horizon equal to `N`.\nNote that, in order to use the function [`numpy.linalg.cond`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.cond.html), you first need to convert `Mb` to be a dense matrix.\nThis can be done as `Mb_dense = Mb.todense()`."},"source":"It's time to replicate the plot of the lost digits in the case of direct transcription.\nNow we look at the condition number of $\\mathbb{M}$.\n\nDefine a list with name `lost_bits_transcription` which contains `N_max = 100` elements.\nFor `N` ranging from `1` to `N_max`, the `N`th entry in `lost_bits_transcription` must be logarithm in base 2 of the condition number of $\\mathbb{M}$ (`Mb` in the code) for a time horizon equal to `N`.\nNote that, in order to use the function [`numpy.linalg.cond`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.cond.html), you first need to convert `Mb` to be a dense matrix.\nThis can be done as `Mb_dense = Mb.todense()`."},{"block_group":"e7ed66f9e623418d9753a18af05cd10e","cell_type":"code","execution_count":null,"metadata":{"cell_id":"48261eb66a1a4742a4cf0d456c294a90","deepnote_block_group":"e7ed66f9e623418d9753a18af05cd10e","deepnote_cell_type":"code","deepnote_sorting_key":"31","deepnote_source":"# number of bits lost in the inversion of Mb\n# as a function of the time horizon N\nlost_bits_transcription = [np.nan for N in range(1, N_max + 1)]  # modify here"},"outputs":[],"source":"# number of bits lost in the inversion of Mb\n# as a function of the time horizon N\nlost_bits_transcription = [np.nan for N in range(1, N_max + 1)]  # modify here"},{"block_group":"86020e8b6b1441fcad1c8ec06304daf7","cell_type":"markdown","execution_count":null,"metadata":{"cell_id":"38d665f1a3fa481f84b14d9cffedd3e7","deepnote_block_group":"86020e8b6b1441fcad1c8ec06304daf7","deepnote_cell_type":"markdown","deepnote_sorting_key":"32","deepnote_source":"Does this plot look better than the direct-shooting one?\nWhich kind of law does this curve follow: constant, logarithmic, linear, polynomial, or exponential?"},"source":"Does this plot look better than the direct-shooting one?\nWhich kind of law does this curve follow: constant, logarithmic, linear, polynomial, or exponential?"},{"block_group":"2006007b71bf43059fdd60bd7c0bc7cb","cell_type":"code","execution_count":null,"metadata":{"cell_id":"162a698de66e4c43bd0ba1dccb3e9b06","deepnote_block_group":"2006007b71bf43059fdd60bd7c0bc7cb","deepnote_cell_type":"code","deepnote_sorting_key":"33","deepnote_source":"# plot your results\nplt.figure()\nplot_lost_bits(lost_bits_transcription)"},"outputs":[],"source":"# plot your results\nplt.figure()\nplot_lost_bits(lost_bits_transcription)"},{"block_group":"e685967307af44449ec2d964e8c45a6e","cell_type":"markdown","execution_count":null,"metadata":{"cell_id":"4aefe19d601f4df0923668a3b3b48baf","deepnote_block_group":"e685967307af44449ec2d964e8c45a6e","deepnote_cell_type":"markdown","deepnote_sorting_key":"34","deepnote_source":"## Dynamic Programming Recursion, a.k.a. Riccati Recursion\n\nEven if we did our best to exploit the sparsity in the linear system of the direct transcription method, this approach was still quite slow.\nIt turns out that the particular structure of the matrix $\\mathbb{M}$ can be exploited even more and the linear system $\\mathbb{M} \\mathbb{z} = \\mathbb{x}_0$ can be solved much faster.\n\nThe name of the technique to do this is \"Riccati recursion.\"\nYou can find more details in [this paper](https://link.springer.com/article/10.1023/A:1021711402723) or in [these lecture notes](https://web.stanford.edu/class/ee363/notes/riccati-derivation.pdf).\n(The second should be an easier read.)\nThe main idea is to invert the matrix $\\mathbb{M}$ one block per time, starting from the bottom right, and moving up; in a similar spirit of dynamics programming.\n\nThis idea has had a big impact in robotics, allowing the solution of optimal control problems in real time.\nResearchers from ETH Zurich have done an amazing job at pushing techniques like this to the limit (see, for example, [this paper](https://arxiv.org/abs/1710.04029)).\nHere is their quadruped robot ANYmal.\nIts control software takes great advantage of techniques like the ones we studied in this notebook."},"source":"## Dynamic Programming Recursion, a.k.a. Riccati Recursion\n\nEven if we did our best to exploit the sparsity in the linear system of the direct transcription method, this approach was still quite slow.\nIt turns out that the particular structure of the matrix $\\mathbb{M}$ can be exploited even more and the linear system $\\mathbb{M} \\mathbb{z} = \\mathbb{x}_0$ can be solved much faster.\n\nThe name of the technique to do this is \"Riccati recursion.\"\nYou can find more details in [this paper](https://link.springer.com/article/10.1023/A:1021711402723) or in [these lecture notes](https://web.stanford.edu/class/ee363/notes/riccati-derivation.pdf).\n(The second should be an easier read.)\nThe main idea is to invert the matrix $\\mathbb{M}$ one block per time, starting from the bottom right, and moving up; in a similar spirit of dynamics programming.\n\nThis idea has had a big impact in robotics, allowing the solution of optimal control problems in real time.\nResearchers from ETH Zurich have done an amazing job at pushing techniques like this to the limit (see, for example, [this paper](https://arxiv.org/abs/1710.04029)).\nHere is their quadruped robot ANYmal.\nIts control software takes great advantage of techniques like the ones we studied in this notebook."},{"block_group":"b78256b2a1cb4b5f9e0755f4d2db123d","cell_type":"code","execution_count":null,"metadata":{"cell_id":"ecf4ab6a6e6742c5addecc4a381021b5","deepnote_block_group":"b78256b2a1cb4b5f9e0755f4d2db123d","deepnote_cell_type":"code","deepnote_sorting_key":"35","deepnote_source":"from IPython.display import IFrame\n\nIFrame(src=\"https://www.youtube.com/embed/m1-s8iOJaI4\", width=\"640\", height=\"360\")"},"outputs":[],"source":"from IPython.display import IFrame\n\nIFrame(src=\"https://www.youtube.com/embed/m1-s8iOJaI4\", width=\"640\", height=\"360\")"},{"block_group":"f6dbc2ee8af246a3adfd8895e24d377a","cell_type":"markdown","execution_count":null,"metadata":{"cell_id":"1354992abda84bae890a576f981b1f5f","deepnote_block_group":"f6dbc2ee8af246a3adfd8895e24d377a","deepnote_cell_type":"markdown","deepnote_sorting_key":"36","deepnote_source":"The Riccati recursion idea can be applied very broadly; all the way to nonlinear constrained optimization.\nHowever, in our simple settings, it can be seen that it is equivalent to the dynamic programming recursion [which we have seen in class](https://underactuated.mit.edu/lqr.html#dt_riccati).\nHave a look at [these lecture notes](https://web.stanford.edu/class/ee363/notes/riccati-derivation.pdf) if you want to convince yourself about this equivalence.\n\nWe initialize $n = N$ and the cost-to-go matrix $\\mathbf{S}[N] = \\mathbf{Q}_N$.\nThen we go backwards in time computing\n$$\n\\mathbf{S}[n-1] =\n\\mathbf{Q} +\n\\mathbf{A}^T\\mathbf{S}[n]\\mathbf{A} -\n\\mathbf{A}^T\\mathbf{S}[n]\\mathbf{B}\n(\\mathbf{R} + \\mathbf{B}^T\\mathbf{S}[n]\\mathbf{B})^{-1}\n\\mathbf{B}^T\\mathbf{S}[n]\\mathbf{A}\n$$\nuntil we get $\\mathbf{S}[0]$.\n\nThis is the last piece of code you are asked to write.\nA function called `riccati_recursion` which takes as inputs `(A, B, Q, R, QN, N)` and returns the optimal cost-to-go matrix $\\mathbf{S}[0]$ for the finite-horizon LQR with $N$ steps.\nDo this by implementing the recursion above."},"source":"The Riccati recursion idea can be applied very broadly; all the way to nonlinear constrained optimization.\nHowever, in our simple settings, it can be seen that it is equivalent to the dynamic programming recursion [which we have seen in class](https://underactuated.mit.edu/lqr.html#dt_riccati).\nHave a look at [these lecture notes](https://web.stanford.edu/class/ee363/notes/riccati-derivation.pdf) if you want to convince yourself about this equivalence.\n\nWe initialize $n = N$ and the cost-to-go matrix $\\mathbf{S}[N] = \\mathbf{Q}_N$.\nThen we go backwards in time computing\n$$\n\\mathbf{S}[n-1] =\n\\mathbf{Q} +\n\\mathbf{A}^T\\mathbf{S}[n]\\mathbf{A} -\n\\mathbf{A}^T\\mathbf{S}[n]\\mathbf{B}\n(\\mathbf{R} + \\mathbf{B}^T\\mathbf{S}[n]\\mathbf{B})^{-1}\n\\mathbf{B}^T\\mathbf{S}[n]\\mathbf{A}\n$$\nuntil we get $\\mathbf{S}[0]$.\n\nThis is the last piece of code you are asked to write.\nA function called `riccati_recursion` which takes as inputs `(A, B, Q, R, QN, N)` and returns the optimal cost-to-go matrix $\\mathbf{S}[0]$ for the finite-horizon LQR with $N$ steps.\nDo this by implementing the recursion above."},{"block_group":"ebc5dec958354137bfd71bdb12c88b1d","cell_type":"code","execution_count":null,"metadata":{"cell_id":"4d6ccb2eb73d42dda858f4bdf5dbaf43","deepnote_block_group":"ebc5dec958354137bfd71bdb12c88b1d","deepnote_cell_type":"code","deepnote_sorting_key":"37","deepnote_source":"# implementation of the Riccati recursion\n\n\ndef riccati_recursion(A, B, Q, R, QN, N):\n    S = QN\n    for n in range(N):\n        S = S  # modify here\n    return S"},"outputs":[],"source":"# implementation of the Riccati recursion\n\n\ndef riccati_recursion(A, B, Q, R, QN, N):\n    S = QN\n    for n in range(N):\n        S = S  # modify here\n    return S"},{"block_group":"5d5e995a68bc441cb0d39de68be750b5","cell_type":"markdown","execution_count":null,"metadata":{"cell_id":"4022fe680a9a476898d889778d19e20d","deepnote_block_group":"5d5e995a68bc441cb0d39de68be750b5","deepnote_cell_type":"markdown","deepnote_sorting_key":"38","deepnote_source":"Here is the same old plot of finite-horizon LQR vs infinite-horizon LQR.\nIf you have done things correctly, this should be super fast and numerically very stable.\nWe push the maximum time horizon `N_max` all the way to `500` here."},"source":"Here is the same old plot of finite-horizon LQR vs infinite-horizon LQR.\nIf you have done things correctly, this should be super fast and numerically very stable.\nWe push the maximum time horizon `N_max` all the way to `500` here."},{"block_group":"28f5de8362f541eab5c663dc118885d1","cell_type":"code","execution_count":null,"metadata":{"cell_id":"05ff249d366c4dd1aef6a7ec44f7e5b4","deepnote_block_group":"28f5de8362f541eab5c663dc118885d1","deepnote_cell_type":"code","deepnote_sorting_key":"39","deepnote_source":"# implementation of the Riccati recursion\n# function that given the system state x0 (together with:\n# the dynamical system matrices A, B; the objective weights\n# Q, R, QN; and the controller horizon N) returns the cost\n# to go of the finite-horizon LQR\n\n\ndef get_J_star_N_riccati(A, B, Q, R, QN, N, x0):\n    S = riccati_recursion(A, B, Q, R, QN, N)\n    return x0.dot(S).dot(x0)\n\n\n# get cost to go as a function of N\nN_max = 500\nJ_star_N_riccati = [\n    get_J_star_N_riccati(A, B, Q, R, QN, N, x0) for N in range(1, N_max + 1)\n]\n\n# plot finite horizon vs infinite horizon\nplt.figure()\nplot_J_star(J_star_N_riccati, J_star_inf)"},"outputs":[],"source":"# implementation of the Riccati recursion\n# function that given the system state x0 (together with:\n# the dynamical system matrices A, B; the objective weights\n# Q, R, QN; and the controller horizon N) returns the cost\n# to go of the finite-horizon LQR\n\n\ndef get_J_star_N_riccati(A, B, Q, R, QN, N, x0):\n    S = riccati_recursion(A, B, Q, R, QN, N)\n    return x0.dot(S).dot(x0)\n\n\n# get cost to go as a function of N\nN_max = 500\nJ_star_N_riccati = [\n    get_J_star_N_riccati(A, B, Q, R, QN, N, x0) for N in range(1, N_max + 1)\n]\n\n# plot finite horizon vs infinite horizon\nplt.figure()\nplot_J_star(J_star_N_riccati, J_star_inf)"},{"block_group":"6fad090577624a5aa4e1db01014a003c","cell_type":"markdown","execution_count":null,"metadata":{"cell_id":"19a9f71dc47446b5b38d87cd316a5329","deepnote_block_group":"6fad090577624a5aa4e1db01014a003c","deepnote_cell_type":"markdown","deepnote_sorting_key":"40","deepnote_source":"## Take-Home Messages\n\nSummarizing the main lessons of the notebook:\n- Linear algebra can be tedious, but is a fundamental issue in trajectory optimization.\n- Direct transcription leads to bigger optimization problems than direct shooting, but these are better conditioned and can be solved very fast using specialized techniques (Riccati recursion)."},"source":"## Take-Home Messages\n\nSummarizing the main lessons of the notebook:\n- Linear algebra can be tedious, but is a fundamental issue in trajectory optimization.\n- Direct transcription leads to bigger optimization problems than direct shooting, but these are better conditioned and can be solved very fast using specialized techniques (Riccati recursion)."},{"block_group":"06dcd05bc0be485a8dc8f6432e5b3bd1","cell_type":"markdown","execution_count":null,"metadata":{"cell_id":"edfa8c8e6c594bf3b7494088af9fd901","deepnote_block_group":"06dcd05bc0be485a8dc8f6432e5b3bd1","deepnote_cell_type":"markdown","deepnote_sorting_key":"41","deepnote_source":"## Autograding\nYou can check your work by running the following cell."},"source":"## Autograding\nYou can check your work by running the following cell."},{"block_group":"2ad9e36affef4dae9fb20261421926e6","cell_type":"code","execution_count":null,"metadata":{"cell_id":"8ab12d64810a460986f968663d25d232","deepnote_block_group":"2ad9e36affef4dae9fb20261421926e6","deepnote_cell_type":"code","deepnote_sorting_key":"42","deepnote_source":"from underactuated.exercises.grader import Grader\nfrom underactuated.exercises.trajopt.test_shooting_vs_transcription import (\n    TestShootingVsTranscription,\n)\n\nGrader.grade_output([TestShootingVsTranscription], [locals()], \"results.json\")\nGrader.print_test_results(\"results.json\")"},"outputs":[],"source":"from underactuated.exercises.grader import Grader\nfrom underactuated.exercises.trajopt.test_shooting_vs_transcription import (\n    TestShootingVsTranscription,\n)\n\nGrader.grade_output([TestShootingVsTranscription], [locals()], \"results.json\")\nGrader.print_test_results(\"results.json\")"}],
        "metadata": {"deepnote_notebook_id":"ba4ba0c6b8314bca94f873219a3d0ee3"},
        "nbformat": "4",
        "nbformat_minor": "0",
        "version": "0"
      }